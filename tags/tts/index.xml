<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TTS - 标签 - XBruce Blog</title>
    <link>https://ansha886.github.io/tags/tts/</link>
    <description>@xbruce&#39;s works</description>
    <generator>Hugo 0.134.3 &amp; FixIt v0.3.15</generator>
    <language>en</language>
    <managingEditor>licheng0601@gmail.com (Bruce)</managingEditor>
    <webMaster>licheng0601@gmail.com (Bruce)</webMaster>
    <lastBuildDate>Wed, 25 Dec 2024 13:52:49 +0800</lastBuildDate>
    <atom:link href="https://ansha886.github.io/tags/tts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>一个用Gemini多模态实时API和WebRTC结合构建的语音AI应用示例：gemini-webrtc-web-simple</title>
      <link>https://ansha886.github.io/posts/gemini-webrtc-web-simple/</link>
      <pubDate>Wed, 25 Dec 2024 13:52:49 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/gemini-webrtc-web-simple/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;&lt;strong&gt;一个用Gemini多模态实时API和WebRTC结合构建的语音AI应用示例：gemini-webrtc-web-simple&lt;/strong&gt; 低延迟、声音质量更好，对于需要处理实时媒体流的应用比较友好&lt;/p&gt;</description>
    </item>
    <item>
      <title>VALL-E X：微软最新开源多语言文本到语音合成和语音克隆模型</title>
      <link>https://ansha886.github.io/posts/vall-e-x/</link>
      <pubDate>Mon, 16 Dec 2024 14:52:01 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/vall-e-x/</guid>
      <category domain="https://ansha886.github.io/categories/llm/">LLM</category>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;VALL-E X 是 Microsoft 提出的一个令人惊叹的多语言文本转语音 (TTS) 模型，虽然 Microsoft 最初在其研究论文中发布了该模型，但他们没有发布任何代码或预训练模型，团队接受了重现结果的挑战。训练我们自己的模型。&lt;/p&gt;</description>
    </item>
    <item>
      <title>FreeStyle自由！西工大和微软等出的一个说唱(Rap)生成模型：Freestyler，可以根据歌词和伴奏直接生成说唱人声</title>
      <link>https://ansha886.github.io/posts/freestyler/</link>
      <pubDate>Mon, 16 Dec 2024 09:12:54 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/freestyler/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;FreeStyle自由！西工大和微软等出的一个说唱(Rap)生成模型：Freestyler，可以根据歌词和伴奏直接生成说唱人声&lt;/p&gt;</description>
    </item>
    <item>
      <title>音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度</title>
      <link>https://ansha886.github.io/posts/float/</link>
      <pubDate>Wed, 04 Dec 2024 10:43:04 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/float/</guid>
      <category domain="https://ansha886.github.io/categories/llm/">LLM</category>
      <description>&lt;p&gt;&lt;strong&gt;这个效果非常可以，音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度&lt;/strong&gt;&#xA;一张源人物肖像图片+驱动音频，生成可以包含情感表现的面部动作并与音频同步的说话人视频它解决了时间连续的视频生成、由于迭代采样导致速度慢，这两个关键问题&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
