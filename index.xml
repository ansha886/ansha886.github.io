<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>XBruce Blog</title>
    <link>https://ansha886.github.io/</link>
    <description>@xbruce&#39;s works</description>
    <generator>Hugo 0.134.3 &amp; FixIt v0.3.15</generator>
    <language>en</language>
    <managingEditor>licheng0601@gmail.com (Bruce)</managingEditor>
    <webMaster>licheng0601@gmail.com (Bruce)</webMaster>
    <lastBuildDate>Mon, 13 Jan 2025 10:52:36 +0800</lastBuildDate>
    <atom:link href="https://ansha886.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>基于WebRTC的AI语音助手openai-realtime-api-nextjs 打造实时语音对话新体验</title>
      <link>https://ansha886.github.io/posts/openai-realtime-api-nextjs/</link>
      <pubDate>Mon, 13 Jan 2025 10:52:36 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/openai-realtime-api-nextjs/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;基于OpenAI实时API和WebRTC的AI语音助手支持多种语言的实时语音转录对话，并可集成工具扩展应用能力，如获取时间和访问网站&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款基于WebRTC的AI语音助手：openai-realtime-api-nextjs，实时语音对话&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;用OpenAI实时API和WebRTC实现实时语音转录对话，支持英语、西班牙语、法语、中文等多种语言&lt;/p&gt;&#xA;&lt;p&gt;支持工具调用， 可以集成各种客户端工具扩展应用能力，比如获取当前时间、访问网站、复制文本等&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/cameronking4/openai-realtime-api-nextjs&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/cameronking4/openai-realtime-api-nextjs&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/openai-realtime-api-nextjs1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/openai-realtime-api-nextjs1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/openai-realtime-api-nextjs1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/openai-realtime-api-nextjs1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/openai-realtime-api-nextjs1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/openai-realtime-api-nextjs1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>唇形同步模型lipsync-1.9测试版发布 实现高质量唇形同步体验</title>
      <link>https://ansha886.github.io/posts/lipsync-1.9/</link>
      <pubDate>Mon, 13 Jan 2025 10:51:13 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/lipsync-1.9/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;lipsync-1.9测试版是一款高质量的唇形同步模型，支持零样本学习，无需训练数据，可在真实视频、动画和AI生成的视频中自然生成和编辑语音。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;sync最新出的其唇形同步模型lipsync-1.9测试版，效果看起来非常不错，唇形同步的质量很高&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;零样本学习，无需任何训练数据， 可以在真实视频、动画以及AI生成的视频中，无缝生成比较自然的语音，还可以编辑语音&lt;/p&gt;&#xA;&lt;p&gt;地址：&lt;a href=&#34;https://sync.so/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://sync.so/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/lipsync-1.9-1&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/lipsync-1.9-1&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/lipsync-1.9-1?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/lipsync-1.9-1?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/lipsync-1.9-1?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/lipsync-1.9-1&#34; class=&#34;suffix-invalid suffix-invalid__small suffix-invalid__large&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>英伟达开源智能文档处理工具nv-ingest 高效提取和结构化复杂文档信息</title>
      <link>https://ansha886.github.io/posts/nv-ingest/</link>
      <pubDate>Mon, 13 Jan 2025 10:48:24 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/nv-ingest/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;英伟达开源的nv-ingest工具能够高效处理PDF、Word、PPT和图像等复杂文档，支持同时处理多个文档并提取页面上的表格、图表、图像和文本等内容类型。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;英伟达开源的一款智能文档信息提取及结构化工具：nv-ingest，能高效处理大规模的PDF、Word、PPT以及图像等复杂的文档，并结构化输出&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它可以同时处理多个文档，并把每个文档分成独立的页面，能识别页面上表格、图表、图像以及文本等不同的内容类型，分别提取出来&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/NVIDIA/nv-ingest&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/NVIDIA/nv-ingest&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/nv-ingest1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/nv-ingest1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/nv-ingest1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/nv-ingest1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/nv-ingest1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/nv-ingest1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>多身份定制化视频生成项目Ingredients解析 输入图像和文字即可生成个性化视频</title>
      <link>https://ansha886.github.io/posts/ingredients/</link>
      <pubDate>Mon, 13 Jan 2025 10:47:03 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/ingredients/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;Ingredients是一个开源的视频生成项目，能够输入多张人物图像和文字描述，生成包含这些人物的视频，效果自然流畅，支持同时处理多个人物图像。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷，一个多身份定制化视频生成项目：Ingredients，输入多张人物图像+文字描述，它可以输出包含这些人物的视频&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以同时处理多个人物图像 每个人物的身份特征保持不变 生成效果相对自然流畅&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/feizc/Ingredients&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/feizc/Ingredients&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Ingredients.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Ingredients.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Ingredients.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Ingredients.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Ingredients.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Ingredients.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>STAR：南京大学与字节跳动开源的视频清晰度提升工具，兼顾细节与时间一致性</title>
      <link>https://ansha886.github.io/posts/star/</link>
      <pubDate>Fri, 10 Jan 2025 10:15:54 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/star/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;STAR是一款开源工具，能在提高视频分辨率的同时保持时间一致性和细节完整性，智能调整清晰度，解决画面连续性和真实感问题。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;南京大学、字节等开源的一款提高视频清晰度的工具：STAR，它能在提高分辨率的同时，保持视频时间一致性和细节完整性，没有细节丢失、运动不自然的问题&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它可以根据视频的不同部分，智能调整清晰度力度，以保证整体的清晰度，又避免过度锐化导致画面不自然&lt;/p&gt;&#xA;&lt;p&gt;它用文本到视频模型学习到的视觉特征和时空信息来增强超分辨率过程，解决了画面连续性，使视频前后帧之间流畅，不会跳动，以及视频真实感的问题&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/NJU-PCALab/STAR&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/NJU-PCALab/STAR&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/STAR1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/STAR1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/STAR1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/STAR1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/STAR1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/STAR1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Company Researcher：一键搜索企业信息的研究助手，轻松获取公司综合资料</title>
      <link>https://ansha886.github.io/posts/company-researcher/</link>
      <pubDate>Fri, 10 Jan 2025 10:14:26 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/company-researcher/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;一键搜索企业信息，一款企业信息研究助手：Company Researcher，输入公司网址，自动收集展示该公司的综合信息 信息来源包括网站子页面、LinkedIn数据、财务信息，新闻报道、维基百科信息、社交媒体Twitter、YouTube、TikTok、Reddit、GitHub等&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一键搜索企业信息，一款企业信息研究助手：Company Researcher，输入公司网址，自动收集展示该公司的综合信息&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;信息来源包括网站子页面、LinkedIn数据、财务信息，新闻报道、维基百科信息、社交媒体Twitter、YouTube、TikTok、Reddit、GitHub等&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/exa-labs/company-researcher&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/exa-labs/company-researcher&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Company%20Researcher.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Company%20Researcher.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Company%20Researcher.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Company%20Researcher.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Company%20Researcher.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Company%20Researcher.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Whisk：Google Labs推出的AI图像生成工具，融合角色、场景和风格自动生成创意图像</title>
      <link>https://ansha886.github.io/posts/whisk/</link>
      <pubDate>Fri, 10 Jan 2025 10:12:35 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/whisk/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;Google Labs推出的AI图像生成工具Whisk，可以通过输入角色、场景和风格的三张图像，自动生成新图像，基于Gemini生成详细描述并使用Google Imagen 3模型进行图像生成，但目前存在使用国家限制。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Google Labs最新推出的AI图像生成工具非常酷，Whisk，给它角色、场景、风格三张图像，它可以自动构图生成非常棒的新图像&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它基于Gemini自动为给定的图像生成详细描述，再将描述输入到Google Imagen 3图像生成模型里生成图像&lt;/p&gt;&#xA;&lt;p&gt;不过目前有使用国家限制 使用地址：&lt;a href=&#34;https://labs.google/fx/tools/whisk/unsupported-country&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://labs.google/fx/tools/whisk/unsupported-country&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk2.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk2.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk2.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk2.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk2.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk2.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk3.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk3.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk3.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk3.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk3.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Whisk3.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Amurex：首款开源AI会议助手，支持实时建议、会议总结和自动化跟进任务</title>
      <link>https://ansha886.github.io/posts/amurex/</link>
      <pubDate>Fri, 10 Jan 2025 09:22:24 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/amurex/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;首款开源AI会议助手amurex提供实时建议、自动记录会议内容、生成总结和邮件跟进，涵盖全流程会议辅助&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷！首款开源的AI会议助手：amurex，它能提供实时会议建议、自动记录会议内容生成总结、会议回顾、一键生成和发送邮件跟进会议事项&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它涵盖了从会议进行中的实时建议，到会议后的总结和后续跟进，提供全流程会议辅助&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/thepersonalaicompany/amurex&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/thepersonalaicompany/amurex&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/amurex1.gif&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/amurex1.gif&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/amurex1.gif?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/amurex1.gif?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/amurex1.gif?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/amurex1.gif&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/amurex2.gif&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/amurex2.gif&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/amurex2.gif?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/amurex2.gif?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/amurex2.gif?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/amurex2.gif&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lobe Vidol：互动式虚拟偶像构建项目，支持文字聊天、语音视频对话及角色跳舞</title>
      <link>https://ansha886.github.io/posts/lobe-vidol/</link>
      <pubDate>Thu, 09 Jan 2025 09:05:57 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/lobe-vidol/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;Lobe Vidol是一个开源项目，允许用户创建互动式虚拟偶像，支持文字聊天、语音视频对话和角色跳舞，用户可以上传3D模型或使用现成角色模型并自定义动作和反应。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一个互动式虚拟偶像的构建项目：Lobe Vidol，可以进行文字聊天、语音视频对话，支持角色跳舞&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以上传3D模型或使用现成的角色模型创建虚拟角色，可以自定义角色的动作和反应&lt;/p&gt;&#xA;&lt;p&gt;支持更换舞台和背景，点击角色互动&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/lobehub/lobe-vidol&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/lobehub/lobe-vidol&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>LatentSync：字节跳动开源的端到端自然唇形同步框架</title>
      <link>https://ansha886.github.io/posts/latentsync/</link>
      <pubDate>Wed, 08 Jan 2025 12:19:13 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/latentsync/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;字节跳动开源的一个唇形同步项目：LatentSync，是一个端到端的唇形同步框架，效果比较自然，连贯性非常好&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;字节跳动开源的一个唇形同步项目：LatentSync，是一个端到端的唇形同步框架，效果比较自然，连贯性非常好&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/bytedance/LatentSync&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/bytedance/LatentSync&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
