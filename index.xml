<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>XBruce Blog</title>
    <link>https://ansha886.github.io/</link>
    <description>@xbruce&#39;s works</description>
    <generator>Hugo 0.134.3 &amp; FixIt v0.3.15</generator>
    <language>en</language>
    <managingEditor>licheng0601@gmail.com (Bruce)</managingEditor>
    <webMaster>licheng0601@gmail.com (Bruce)</webMaster>
    <lastBuildDate>Fri, 17 Jan 2025 10:41:52 +0800</lastBuildDate>
    <atom:link href="https://ansha886.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>国科大×通义实验室：RAIN系统实现实时动画生成！消费级设备就能运行，无限长视频动画生成，流畅又精准，动画领域的新标杆！</title>
      <link>https://ansha886.github.io/posts/rain/</link>
      <pubDate>Fri, 17 Jan 2025 10:41:52 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/rain/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;酷，中国科学技术大学和通义实验室出的一款可以在消费级设备上实时动画生成的系统：RAIN，且能生成无限长视频动画，流畅稳定性，准确性和一致性非常好&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷，中国科学技术大学和通义实验室出的一款可以在消费级设备上实时动画生成的系统：RAIN，且能生成无限长视频动画，流畅稳定性，准确性和一致性非常好&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;支持实时转换表情以及头部动作&lt;/p&gt;&#xA;&lt;p&gt;主页：&lt;a href=&#34;https://pscgylotti.github.io/pages/RAIN/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://pscgylotti.github.io/pages/RAIN/&lt;/a&gt;&#xA;github（代码陆续放出）：&lt;a href=&#34;https://github.com/Pscgylotti/RAIN&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/Pscgylotti/RAIN&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>OmAgent来了：快速打造“能看会听还会说”的AI助手！一个专为开发智能助手的工具，让AI开发简单又高效。</title>
      <link>https://ansha886.github.io/posts/omagent/</link>
      <pubDate>Fri, 17 Jan 2025 10:40:10 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/omagent/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;OmAgent是一个开源工具，支持多模态数据处理，整合多种模型，提供图的工作流编排和多种思维推理方式，能够快速开发智能AI助手。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款可以快速开发&amp;quot;会看会听会说&amp;quot;的AI助手的工具：OmAgent&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;原生支持多模态数据，文本、图像、视频和音频，能整合各种模型，VLM、计算机视觉模型和实时API，可以构建能处理多种信息类型的智能体&lt;/p&gt;&#xA;&lt;p&gt;提供基于图的工作流编排引擎和多种内存类型，实现上下文推理&lt;/p&gt;&#xA;&lt;p&gt;包含多种思维推理方式，ReAct、CoT、SC-Cot等，能处理复杂任务&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/om-ai-lab/OmAgent&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/om-ai-lab/OmAgent&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>智谱新作：GLM-Realtime，多模态互动像开挂一样顺滑！实时视频理解、语音交互，还有清唱功能和长达2分钟的记忆，Function Call也安排上了！</title>
      <link>https://ansha886.github.io/posts/glm-realtime/</link>
      <pubDate>Fri, 17 Jan 2025 10:37:43 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/glm-realtime/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;智谱发布了GLM-Realtime，一个全新的端到端多模态模型，支持近乎实时的视频理解、语音交互、清唱功能以及长达2分钟的记忆和Function Call功能，现阶段可通过API免费调用。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷，智谱刚刚发布了其全新端到端多模态模型：GLM-Realtime，近乎实时的视频理解与语音交互，融入了清唱功能，支持长达2分钟的记忆及Function Call功能&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;GLM-Realtime在实现完全实时交互的基础上，进一步支持Function Call功能，这使其不仅能够依靠自身知识和能力，还能灵活调用外部知识和工具，拓展更广泛的应用场景&lt;/p&gt;&#xA;&lt;p&gt;API： &lt;a href=&#34;http://bigmodel.cn/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;&lt;/a&gt;&lt;a href=&#34;http://bigmodel.cn&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;http://bigmodel.cn&lt;/a&gt;，现阶段可以免费调用&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>微软又放大招！AI设计新材料，MatterGen帮你一键生成！用需求描述就能设计新材料，这款开源模型让材料研发更高效、更智能。</title>
      <link>https://ansha886.github.io/posts/mattergen/</link>
      <pubDate>Fri, 17 Jan 2025 10:34:52 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/mattergen/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;微软开源了MatterGen，一个AI驱动的材料生成模型，可以根据需求描述生成具有多种属性的新材料，开启了材料设计的新范式。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;厉害，微软刚刚开源了一个用AI设计新材料的模型：MatterGen，它可以根据需求描述，直接生成新材料&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它可以生成具有化学、机械、电子或磁性属性的材料，或多种特性的组合&lt;/p&gt;&#xA;&lt;p&gt;MatterGen开启了材料生成新范式，通过生成式AI辅助材料设计，可以更高效地探索材料，突破已知材料的限制&lt;/p&gt;&#xA;&lt;p&gt;博客：&lt;a href=&#34;https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;代码：&lt;a href=&#34;https://github.com/microsoft/mattergen&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/microsoft/mattergen&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI行政助手出场：帮你搞定邮件、日程和日历！executive-ai-assistant，这款AI工具监控邮件、自动回复、安排日程，职场人的效率神器。</title>
      <link>https://ansha886.github.io/posts/executive-ai-assistant/</link>
      <pubDate>Thu, 16 Jan 2025 10:30:48 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/executive-ai-assistant/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;executive-ai-assistant是一款AI助手，能够监控工作邮件、自动回复、安排日程和管理日历，支持个性化设置和会议时间的智能安排。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一个可以帮你处理工作邮件和日程的AI助手，一个行政助手：executive-ai-assistant，可以邮件监控和自动回复，进行日程安排和日历管理&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以监控指定邮箱，读取邮件，根据设定规则对邮件进行分类，比如需要忽略的、通知用户的、自动回复的等&lt;/p&gt;&#xA;&lt;p&gt;自动查看日历并找到合适的时间段，可以根据用户的偏好安排会议时间&lt;/p&gt;&#xA;&lt;p&gt;支持个性化设置，比如基本信息、邮件回复风格、时区和会议偏好等&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/langchain-ai/executive-ai-assistant&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/langchain-ai/executive-ai-assistant&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>面壁的黑科技来了：MiniCPM-o 2.6，多模态互动直接上 iPad！支持视觉、语音和多模态流式交互，性能媲美 GPT-4o-202405，随时随地体验强大 AI。</title>
      <link>https://ansha886.github.io/posts/minicpm-o-2.6/</link>
      <pubDate>Thu, 16 Jan 2025 10:28:48 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/minicpm-o-2.6/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;MiniCPM-o 2.6是首个支持在iPad等端侧设备进行多模态实时流式交互的模型，具备8B参数量，支持中英双语对话和情感控制，能够实时处理视频和音频流，视觉能力增强，包括OCR和多语言支持。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷！面壁开源了其最新模型：MiniCPM-o 2.6，首个支持在 iPad等端侧设备进行多模态实时流式交互的多模态模型，视觉、语音和多模态流式能力说是达到了GPT-4o-202405级别&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;1、总参数量 8B&lt;/p&gt;&#xA;&lt;p&gt;2、支持可配置声音的中英双语语音对话，同时具备情感、语速、风格控制、端到端声音克隆、角色扮演等进阶能力&lt;/p&gt;&#xA;&lt;p&gt;3、能接受连续视频和音频流，进行实时语音交互。在StreamingBench上，超过了GPT-4o-202408和Claude 3.5 Sonnet&lt;/p&gt;&#xA;&lt;p&gt;4、增强了OCR、可信行为、多语言支持和视频理解等视觉能力&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/OpenBMB/MiniCPM-o/tree/main&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/OpenBMB/MiniCPM-o/tree/main&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1&#34; class=&#34;suffix-invalid suffix-invalid__small suffix-invalid__large&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2&#34; class=&#34;suffix-invalid suffix-invalid__small suffix-invalid__large&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MiniMax大招：超长上下文模型强势来袭！最新开源的 MiniMax-Text-01 和 MiniMax-VL-01 模型，支持超长 400 万 token 上下文，AI Agent 领域新标杆。</title>
      <link>https://ansha886.github.io/posts/minimax/</link>
      <pubDate>Thu, 16 Jan 2025 10:26:20 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/minimax/</guid>
      <category domain="https://ansha886.github.io/categories/draft/">Draft</category>
      <description>&lt;p&gt;MiniMax开源了两个新模型，MiniMax-Text-01和MiniMax-VL-01，支持400万token的超长上下文，适合AI Agent领域，能够处理长文档和复杂对话，首次实现Lightning Attention机制，总参数量4560亿。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;MiniMax刚刚开源了两个新模型，基础语言模型 MiniMax-Text-01 和视觉多模态模型 MiniMax-VL-01，超长上下文，支持400万token上下文长度，是其他模型的20-32倍，适合AI Agent领域&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它可以一次性分析整个长文档，能记住很长的历史对话，适合比如研究分析、法律或文献文档处理、代码理解等等，需要处理大量信息的场景&lt;/p&gt;&#xA;&lt;p&gt;其首次大规模实现了Lightning Attention机制，能够处理更长的上下文，总参数量4560亿，每次推理激活459亿参数&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/MiniMax-AI/MiniMax-01&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/MiniMax-AI/MiniMax-01&lt;/a&gt;&#xA;博客：&lt;a href=&#34;https://www.minimaxi.com/en/news/minimax-01-series-2&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.minimaxi.com/en/news/minimax-01-series-2&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM即插即用神器：Transformer²，让模型适应新任务快人一步！告别传统微调，这个自适应框架实时调整，让大模型更灵活、更高效地应对新挑战。</title>
      <link>https://ansha886.github.io/posts/transformer/</link>
      <pubDate>Thu, 16 Jan 2025 10:24:59 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/transformer/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;Transformer²是一个自适应框架，能够实时调整LLM以适应新任务，无需传统微调，提升灵活性和效率。通过快速诊断任务类型和选择性调整参数，解决了反复训练的问题。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一个自适应框架：Transformer²，它能即时应变，实时调整LLM适应没见过的任务，无需传统的微调过程，提升LLM在处理新任务时的灵活性和效率&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;实时学习适应，碰到新任务能立即调整，减少了反复训练的问题&lt;/p&gt;&#xA;&lt;p&gt;选择性调整，只调整必要的参数&lt;/p&gt;&#xA;&lt;p&gt;两步处理机制，第一步快速诊断任务类型，第二步根据任务调整处理方式&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/SakanaAI/self-adaptive-llms&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/SakanaAI/self-adaptive-llms&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Transformer%c2%b2.gif&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Transformer².gif&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Transformer%c2%b2.gif?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Transformer%c2%b2.gif?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Transformer%c2%b2.gif?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Transformer².gif&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>社交媒体助手上线：只需给它一个URL，就能帮你搞定平台帖子！一款名叫 social-media-agent 的工具，自动生成社交媒体内容，还能手动调整，轻松提升效率。</title>
      <link>https://ansha886.github.io/posts/social-media-agent/</link>
      <pubDate>Thu, 16 Jan 2025 10:23:46 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/social-media-agent/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;社交媒体自动化助手social-media-agent可以根据给定的URL自动生成Twitter和LinkedIn的帖子，支持内容审核和修改，兼容GitHub、YouTube等源内容，并可与Slack集成。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款社交媒体自动化助手：social-media-agent，给它一个URL，它可以自动给该内容生成社交媒体平台的帖子，可以人工介入审核修改&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;自动读取内容，生成文案+配图，可以自定义文案风格&lt;/p&gt;&#xA;&lt;p&gt;支持生成Twitter和LinkedIn的帖子&lt;/p&gt;&#xA;&lt;p&gt;支持处理比如GitHub、Twitter、YouTube等源内容，支持与Slack集成&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/langchain-ai/social-media-agent&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/langchain-ai/social-media-agent&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/social-media-agent.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/social-media-agent.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/social-media-agent.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/social-media-agent.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/social-media-agent.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/social-media-agent.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>WrenAI：用聊天的方式搞定SQL，还能秒变图表！数据团队的绝佳拍档，问一句话，结果全出来</title>
      <link>https://ansha886.github.io/posts/wrenai/</link>
      <pubDate>Wed, 15 Jan 2025 11:31:28 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/wrenai/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;WrenAI是一款AI数据交互工具，支持自然语言提问并生成SQL查询，提供数据可视化和报表功能，适合多语言用户，支持无缝工作流导出CSV或JSON格式。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款非常棒的AI数据交互工具：WrenAI，你可以用自然语言提问，它能理解你的意图并生成SQL查询，还能把数据转成图表、表格、报表和BI等，非常适合数据团队&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它是一个端到端的解决方案，不只是SQL生成，它提供了从提问到数据可视化、报表生成一套完整流程&lt;/p&gt;&#xA;&lt;p&gt;支持英语、德语、西班牙语、法语、日语、韩语、葡萄牙语、中文等多语言&lt;/p&gt;&#xA;&lt;p&gt;支持语义理解，它能理解数据背后的语义和业务逻辑，生成的SQL查询更精准&lt;/p&gt;&#xA;&lt;p&gt;提供无缝端到端的工作流，你可以输出CSV或JSON格式导入到Excel或Google表格中进一步使用&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/Canner/WrenAI&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/Canner/WrenAI&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/WrenAI.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/WrenAI.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/WrenAI.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/WrenAI.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/WrenAI.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/WrenAI.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
