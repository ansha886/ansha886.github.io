<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>XBruce Blog</title>
    <link>https://ansha886.github.io/</link>
    <description>@xbruce&#39;s works</description>
    <generator>Hugo 0.134.3 &amp; FixIt v0.3.15</generator>
    <language>en</language>
    <managingEditor>licheng0601@gmail.com (Bruce)</managingEditor>
    <webMaster>licheng0601@gmail.com (Bruce)</webMaster>
    <lastBuildDate>Thu, 09 Jan 2025 09:05:57 +0800</lastBuildDate>
    <atom:link href="https://ansha886.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lobe Vidol：互动式虚拟偶像构建项目，支持文字聊天、语音视频对话及角色跳舞</title>
      <link>https://ansha886.github.io/posts/lobe-vidol/</link>
      <pubDate>Thu, 09 Jan 2025 09:05:57 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/lobe-vidol/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;Lobe Vidol是一个开源项目，允许用户创建互动式虚拟偶像，支持文字聊天、语音视频对话和角色跳舞，用户可以上传3D模型或使用现成角色模型并自定义动作和反应。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一个互动式虚拟偶像的构建项目：Lobe Vidol，可以进行文字聊天、语音视频对话，支持角色跳舞&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以上传3D模型或使用现成的角色模型创建虚拟角色，可以自定义角色的动作和反应&lt;/p&gt;&#xA;&lt;p&gt;支持更换舞台和背景，点击角色互动&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/lobehub/lobe-vidol&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/lobehub/lobe-vidol&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Lobe%20Vidol.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>LatentSync：字节跳动开源的端到端自然唇形同步框架</title>
      <link>https://ansha886.github.io/posts/latentsync/</link>
      <pubDate>Wed, 08 Jan 2025 12:19:13 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/latentsync/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;字节跳动开源的一个唇形同步项目：LatentSync，是一个端到端的唇形同步框架，效果比较自然，连贯性非常好&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;字节跳动开源的一个唇形同步项目：LatentSync，是一个端到端的唇形同步框架，效果比较自然，连贯性非常好&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/bytedance/LatentSync&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/bytedance/LatentSync&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/LatentSync.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Open Deep Research：自动化主题研究与报告生成的开源AI助手</title>
      <link>https://ansha886.github.io/posts/open-deep-research/</link>
      <pubDate>Wed, 08 Jan 2025 12:10:41 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/open-deep-research/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;Open Deep Research是一款开源AI研究助手，支持自动化研究、报告生成及网页内容提取分析，具备时间过滤搜索功能和多种格式导出选项。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款AI研究助手：Open Deep Research，基于主题自动化研究并生成报告，Gemini Deep Research的开源替代方案&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;搜索、研究、写作自动化，支持网页内容的提取和分析，可以导出PDF、Word、Text多种格式&lt;/p&gt;&#xA;&lt;p&gt;支持带有时间过滤的网页搜索功能，可调整搜索范围和数量，自定义报告风格，自定义提示词引导研究方向等&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/btahir/open-deep-research&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/btahir/open-deep-research&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Open%20Deep%20Research.gif&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Open%20Deep%20Research.gif&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Open%20Deep%20Research.gif?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Open%20Deep%20Research.gif?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Open%20Deep%20Research.gif?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Open%20Deep%20Research.gif&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Browser-Use-WebUI：功能增强版的浏览器AI助手</title>
      <link>https://ansha886.github.io/posts/browser-use-webui/</link>
      <pubDate>Wed, 08 Jan 2025 12:06:28 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/browser-use-webui/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;browser-use-webui是一款增强功能的浏览器AI助手，支持多种LLM，提供Web界面，避免重复登录，支持高清屏幕录制和提示词优化。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于Browser Use的一款浏览器AI助手：browser-use-webui，在原来的基础上做了功能增强&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;提供了一个Web 界面，支持多种browser-use功能&lt;/p&gt;&#xA;&lt;p&gt;扩展了对DeepSeek、Gemini、OpenAI、Azure OpenAI、Anthropic、Ollama等LLM的支持&lt;/p&gt;&#xA;&lt;p&gt;可以使用自己的浏览器，避免重复登录认证问题，支持高清屏幕录制，具备提示词优化能力&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/warmshao/browser-use-webui&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/warmshao/browser-use-webui&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/browser-use-webui1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/browser-use-webui1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/browser-use-webui1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/browser-use-webui1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/browser-use-webui1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/browser-use-webui1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>ImBD：一款高准确率的AI文章检测工具，支持检测AI生成、润色、改写与扩写内容</title>
      <link>https://ansha886.github.io/posts/imbd/</link>
      <pubDate>Wed, 08 Jan 2025 11:59:09 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/imbd/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;ImBD是一款开源AI文章检测工具，能够高效检测文章是否经过AI修改，支持检测纯AI生成和润色、改写、扩写的文本，准确率高达99.96%。其性能在检测不同版本的AI生成文本时显著提升，适合用于论文和稿件的原创性检测。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷，多高校开源的一个AI文章检测工具：ImBD(Imitate Before Detect)，可以检测文章是否被AI修改过，能检测纯AI生成的，还能检测被AI润色、改写、扩写的，准确率高&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;用来检测论文、稿件原创性就非常轻松，它仅使用1000个样本和5分钟的SPO就超过了商业的GPT-Zero&lt;/p&gt;&#xA;&lt;p&gt;检测开源LLM修改文本上提高了13%，检测GPT-3.5和GPT-4o修改的文本上，性能提高了5%和19%&lt;/p&gt;&#xA;&lt;p&gt;支持像改写、扩写、润色都可以，纯AI生成的检测率能到99.96%，改写87.39%，扩写97.58%，润色97.07%&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/Jiaqi-Chen-00/ImBD&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/Jiaqi-Chen-00/ImBD&lt;/a&gt;&#xA;Demo：&lt;a href=&#34;https://ai-detector.fenz.ai/ai-detector&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://ai-detector.fenz.ai/ai-detector&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD2.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD2.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD2.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD2.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD2.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD2.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD3.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD3.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD3.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD3.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD3.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD3.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD4.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD4.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD4.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD4.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD4.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ImBD4.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>多服装虚拟试穿项目：AnyDressing，支持复杂服装组合与高细节贴合</title>
      <link>https://ansha886.github.io/posts/anydressing/</link>
      <pubDate>Mon, 06 Jan 2025 09:26:41 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/anydressing/</guid>
      <category domain="https://ansha886.github.io/categories/agent/">Agent</category>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;AnyDressing是一个多服装虚拟试穿项目，支持同时试穿多件衣服，处理复杂组合，适用于多种场景，且可与其他AI工具配合使用，具备强大的定制性和个性化调整功能。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷，字节和清华的一款多服装虚拟试穿项目：AnyDressing，它支持同时试穿多件衣服，能处理复杂服装组合，看起来细节保持和衣服贴合度比较好&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;1、比如试穿上衣+裤子+外套，一次性完成，可定制性强， 能够处理多种服装组合和个性化文本提示&lt;/p&gt;&#xA;&lt;p&gt;2、适用于各种场景，支持现实风格生成也支持动漫风&lt;/p&gt;&#xA;&lt;p&gt;3、可以和其他AI工具配合使用(ControlNet, LoRA等)，支持文字描述来调整生成效果，比如调整衣服的风格、人物表情等等&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/Crayon-Shinchan/AnyDressing&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/Crayon-Shinchan/AnyDressing&lt;/a&gt;&#xA;项目：&lt;a href=&#34;https://crayon-shinchan.github.io/AnyDressing/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://crayon-shinchan.github.io/AnyDressing/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/AnyDressing.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/AnyDressing.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/AnyDressing.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/AnyDressing.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/AnyDressing.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/AnyDressing.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 视频字幕工具：ai-no-jimaku-gumi，可自动生成多语言翻译字幕</title>
      <link>https://ansha886.github.io/posts/ai-no-jimaku-gumi/</link>
      <pubDate>Mon, 06 Jan 2025 09:23:42 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/ai-no-jimaku-gumi/</guid>
      <category domain="https://ansha886.github.io/categories/video-agent/">Video Agent</category>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;ai-no-jimaku-gumi是一款开源AI工具，能够自动从视频音频中提取语音生成字幕，并支持多种语言翻译，主要输出SRT格式，允许自定义参数设置。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款视频字幕AI工具：ai-no-jimaku-gumi，自动将视频转换成字幕并翻译成多种语言&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;从视频音频中提取语音自动生成字幕 支持包括但不限于英语、日语、中文等多语言翻译&lt;/p&gt;&#xA;&lt;p&gt;目前主要支持SRT字幕格式输出 支持自定义参数&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/Inokinoki/ai-no-jimaku-gumi&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/Inokinoki/ai-no-jimaku-gumi&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ai-no-jimaku-gumi.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ai-no-jimaku-gumi.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ai-no-jimaku-gumi.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/ai-no-jimaku-gumi.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/ai-no-jimaku-gumi.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ai-no-jimaku-gumi.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>一款轻量级的开源AI智能体构建框架：Mainframe-Orchestra，可构建基于LLM任务流程的多智能体团队，支持复杂的工作流程</title>
      <link>https://ansha886.github.io/posts/%E4%B8%80%E6%AC%BE%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9A%84%E5%BC%80%E6%BA%90ai%E6%99%BA%E8%83%BD%E4%BD%93%E6%9E%84%E5%BB%BA%E6%A1%86%E6%9E%B6mainframe-orchestra%E5%8F%AF%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8Ellm%E4%BB%BB%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%9A%84%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%9B%A2%E9%98%9F%E6%94%AF%E6%8C%81%E5%A4%8D%E6%9D%82%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Thu, 02 Jan 2025 11:57:34 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/%E4%B8%80%E6%AC%BE%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9A%84%E5%BC%80%E6%BA%90ai%E6%99%BA%E8%83%BD%E4%BD%93%E6%9E%84%E5%BB%BA%E6%A1%86%E6%9E%B6mainframe-orchestra%E5%8F%AF%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8Ellm%E4%BB%BB%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%9A%84%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%9B%A2%E9%98%9F%E6%94%AF%E6%8C%81%E5%A4%8D%E6%9D%82%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;Mainframe-Orchestra是一个轻量级的开源AI智能体构建框架，支持多智能体团队和复杂工作流程，具备角色专业化、模块化设计和智能编排机制。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款轻量级的开源AI智能体构建框架：Mainframe-Orchestra，可构建基于LLM任务流程的多智能体团队，支持复杂的工作流程&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;1、角色专业化设计，每个智能体都有明确的身份定位，配备专门的工具和技能 2、模块化设计，可以自由组合不同AI及工具，支持多LLM，内置工具集 3、智能编排机制，智能体可以同时是执行者和指挥者，支持动态任务分解&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/mainframecomputer/orchestra&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/mainframecomputer/orchestra&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>一款基于LLM的智能文档处理工具：ExtractThinker</title>
      <link>https://ansha886.github.io/posts/extractthinker/</link>
      <pubDate>Thu, 02 Jan 2025 11:49:02 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/extractthinker/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;ExtractThinker是一款开源的智能文档处理工具，支持PDF、图片和表格等多种格式，具有自定义提取规则、自动分类和异步批量处理功能。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款基于LLM的智能文档处理工具：ExtractThinker&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;支持PDF、图片、表格等多种格式，可以自定义提取规则 自动分类，自动判断文件类型，根据不同的类型提取不同的信息 支持异步处理大文档，批量处理多个文档&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/enoch3712/ExtractThinker&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/enoch3712/ExtractThinker&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>一款优秀的长故事可视化工具——Story-Adapter，它能够自动生成100帧的漫画或动画分镜图，并且在故事的语义一致性方面表现出色。</title>
      <link>https://ansha886.github.io/posts/story-adapter/</link>
      <pubDate>Tue, 31 Dec 2024 09:07:44 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/story-adapter/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <category domain="https://ansha886.github.io/categories/llm/">LLM</category>
      <description>&lt;p&gt;一款优秀的长故事可视化工具——Story-Adapter，它能够自动生成100帧的漫画或动画分镜图，并且在故事的语义一致性方面表现出色。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款不错的长故事可视化工具：Story-Adapter，可以自动生成100帧漫画或动画的分镜图，故事的语义一致性比较好&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;不需要额外训练可以直接用 画面连贯性保持的可以，图片间逻辑清晰，人物场景也能保持一致&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/jwmao1/story-adapter&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/jwmao1/story-adapter&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Story-Adapter.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Story-Adapter.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Story-Adapter.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/Story-Adapter.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/Story-Adapter.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/Story-Adapter.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
