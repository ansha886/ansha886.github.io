<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>XBruce Blog</title>
    <link>https://ansha886.github.io/</link>
    <description>@xbruce&#39;s works</description>
    <generator>Hugo 0.134.3 &amp; FixIt v0.3.15</generator>
    <language>en</language>
    <managingEditor>licheng0601@gmail.com (Bruce)</managingEditor>
    <webMaster>licheng0601@gmail.com (Bruce)</webMaster>
    <lastBuildDate>Sat, 18 Jan 2025 10:03:31 +0800</lastBuildDate>
    <atom:link href="https://ansha886.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>一款专门用于将HTML转为Markdown和JSON格式的小模型：ReaderLM-v2，只有1.5B，性能超过了Qwen2.5-32B、Gemini2-flash、GPT-4o-2024-08-06等</title>
      <link>https://ansha886.github.io/posts/readerlm-v2/</link>
      <pubDate>Sat, 18 Jan 2025 10:03:31 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/readerlm-v2/</guid>
      <category domain="https://ansha886.github.io/categories/draft/">Draft</category>
      <description>&lt;p&gt;ReaderLM-v2是一个1.5B的小模型，专门用于将HTML转换为Markdown和JSON，支持复杂格式和29种语言，适合批量处理网页和自动化数据提取。性能超过多个大型模型。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款专门用于将HTML转为Markdown和JSON格式的小模型：ReaderLM-v2，只有1.5B，性能超过了Qwen2.5-32B、Gemini2-flash、GPT-4o-2024-08-06等&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;1、可以处理长文本，支持复杂格式，比如表格、嵌套列表、LaTeX公式等&lt;/p&gt;&#xA;&lt;p&gt;2、稳定性比较好，没有重复或循环的问题&lt;/p&gt;&#xA;&lt;p&gt;3、支持29种语言，包括英语、中文、日语、韩语、法语、西班牙语、葡萄牙语、德语、意大利语、俄语、越南语、泰语、阿拉伯语等&lt;/p&gt;&#xA;&lt;p&gt;适合需要批量处理网页或自动化网页数据提取的场景&lt;/p&gt;&#xA;&lt;p&gt;HF：&lt;a href=&#34;https://huggingface.co/jinaai/ReaderLM-v2&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://huggingface.co/jinaai/ReaderLM-v2&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-2.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-2.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-2.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-2.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-2.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/ReaderLM-v2-2.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>酷！一款可以对RLHF训练过程可视化的工具：RLLoggingBoard，可以实时显示AI模型训练时的各种数据，分析训练效果</title>
      <link>https://ansha886.github.io/posts/rlloggingboard/</link>
      <pubDate>Sat, 18 Jan 2025 10:01:01 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/rlloggingboard/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;RLLoggingBoard是一款开源工具，可以实时可视化RLHF训练过程中的数据，帮助分析训练效果并定位潜在问题。通过监控token概率和response reward分布，用户可以更直观地了解训练动态。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷！一款可以对RLHF训练过程可视化的工具：RLLoggingBoard，可以实时显示AI模型训练时的各种数据，分析训练效果&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以更直观看到RL训练过程，比如，token概率会随着训练升高或降低情况、response reward分布随着训练的变化情况等&lt;/p&gt;&#xA;&lt;p&gt;当训练不符合预期时，通过监控token粒度的指标来定位可能的问题&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/HarderThenHarder/RLLoggingBoard&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/HarderThenHarder/RLLoggingBoard&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard2.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard2.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard2.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard2.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard2.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RLLoggingBoard2.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>一款辅助阅读和理解科研论文的AI工具，一个科研助手：OpenScholar</title>
      <link>https://ansha886.github.io/posts/openscholar/</link>
      <pubDate>Sat, 18 Jan 2025 09:52:04 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/openscholar/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;OpenScholar是一款AI工具，帮助用户阅读和理解科研论文，自动查找相关论文并以通俗易懂的方式呈现内容，支持标准RAG流程，具备自反思生成能力，解决科研论文数量庞大的问题。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款辅助阅读和理解科研论文的AI工具，一个科研助手：OpenScholar&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它可以基于提问自动查找相关的论文，并把论文内容消化后用通俗易懂的方式回，且会标注信息来源，解决每年新发表的论文太多看不过来的问题&lt;/p&gt;&#xA;&lt;p&gt;支持标准RAG流程，包含检索器+重排序器管道，具备自反思生成能力&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/AkariAsai/OpenScholar&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/AkariAsai/OpenScholar&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar2.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar2.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar2.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar2.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar2.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OpenScholar2.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>国科大×通义实验室：RAIN系统实现实时动画生成！消费级设备就能运行，无限长视频动画生成，流畅又精准，动画领域的新标杆！</title>
      <link>https://ansha886.github.io/posts/rain/</link>
      <pubDate>Fri, 17 Jan 2025 10:41:52 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/rain/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;酷，中国科学技术大学和通义实验室出的一款可以在消费级设备上实时动画生成的系统：RAIN，且能生成无限长视频动画，流畅稳定性，准确性和一致性非常好&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷，中国科学技术大学和通义实验室出的一款可以在消费级设备上实时动画生成的系统：RAIN，且能生成无限长视频动画，流畅稳定性，准确性和一致性非常好&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;支持实时转换表情以及头部动作&lt;/p&gt;&#xA;&lt;p&gt;主页：&lt;a href=&#34;https://pscgylotti.github.io/pages/RAIN/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://pscgylotti.github.io/pages/RAIN/&lt;/a&gt;&#xA;github（代码陆续放出）：&lt;a href=&#34;https://github.com/Pscgylotti/RAIN&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/Pscgylotti/RAIN&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/RAIN.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>OmAgent来了：快速打造“能看会听还会说”的AI助手！一个专为开发智能助手的工具，让AI开发简单又高效。</title>
      <link>https://ansha886.github.io/posts/omagent/</link>
      <pubDate>Fri, 17 Jan 2025 10:40:10 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/omagent/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;OmAgent是一个开源工具，支持多模态数据处理，整合多种模型，提供图的工作流编排和多种思维推理方式，能够快速开发智能AI助手。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一款可以快速开发&amp;quot;会看会听会说&amp;quot;的AI助手的工具：OmAgent&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;原生支持多模态数据，文本、图像、视频和音频，能整合各种模型，VLM、计算机视觉模型和实时API，可以构建能处理多种信息类型的智能体&lt;/p&gt;&#xA;&lt;p&gt;提供基于图的工作流编排引擎和多种内存类型，实现上下文推理&lt;/p&gt;&#xA;&lt;p&gt;包含多种思维推理方式，ReAct、CoT、SC-Cot等，能处理复杂任务&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/om-ai-lab/OmAgent&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/om-ai-lab/OmAgent&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/OmAgent.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>智谱新作：GLM-Realtime，多模态互动像开挂一样顺滑！实时视频理解、语音交互，还有清唱功能和长达2分钟的记忆，Function Call也安排上了！</title>
      <link>https://ansha886.github.io/posts/glm-realtime/</link>
      <pubDate>Fri, 17 Jan 2025 10:37:43 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/glm-realtime/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;智谱发布了GLM-Realtime，一个全新的端到端多模态模型，支持近乎实时的视频理解、语音交互、清唱功能以及长达2分钟的记忆和Function Call功能，现阶段可通过API免费调用。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷，智谱刚刚发布了其全新端到端多模态模型：GLM-Realtime，近乎实时的视频理解与语音交互，融入了清唱功能，支持长达2分钟的记忆及Function Call功能&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;GLM-Realtime在实现完全实时交互的基础上，进一步支持Function Call功能，这使其不仅能够依靠自身知识和能力，还能灵活调用外部知识和工具，拓展更广泛的应用场景&lt;/p&gt;&#xA;&lt;p&gt;API： &lt;a href=&#34;http://bigmodel.cn/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;&lt;/a&gt;&lt;a href=&#34;http://bigmodel.cn&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;http://bigmodel.cn&lt;/a&gt;，现阶段可以免费调用&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/GLM-Realtime1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>微软又放大招！AI设计新材料，MatterGen帮你一键生成！用需求描述就能设计新材料，这款开源模型让材料研发更高效、更智能。</title>
      <link>https://ansha886.github.io/posts/mattergen/</link>
      <pubDate>Fri, 17 Jan 2025 10:34:52 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/mattergen/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;微软开源了MatterGen，一个AI驱动的材料生成模型，可以根据需求描述生成具有多种属性的新材料，开启了材料设计的新范式。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;厉害，微软刚刚开源了一个用AI设计新材料的模型：MatterGen，它可以根据需求描述，直接生成新材料&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它可以生成具有化学、机械、电子或磁性属性的材料，或多种特性的组合&lt;/p&gt;&#xA;&lt;p&gt;MatterGen开启了材料生成新范式，通过生成式AI辅助材料设计，可以更高效地探索材料，突破已知材料的限制&lt;/p&gt;&#xA;&lt;p&gt;博客：&lt;a href=&#34;https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;代码：&lt;a href=&#34;https://github.com/microsoft/mattergen&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/microsoft/mattergen&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MatterGen.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI行政助手出场：帮你搞定邮件、日程和日历！executive-ai-assistant，这款AI工具监控邮件、自动回复、安排日程，职场人的效率神器。</title>
      <link>https://ansha886.github.io/posts/executive-ai-assistant/</link>
      <pubDate>Thu, 16 Jan 2025 10:30:48 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/executive-ai-assistant/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;executive-ai-assistant是一款AI助手，能够监控工作邮件、自动回复、安排日程和管理日历，支持个性化设置和会议时间的智能安排。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;一个可以帮你处理工作邮件和日程的AI助手，一个行政助手：executive-ai-assistant，可以邮件监控和自动回复，进行日程安排和日历管理&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以监控指定邮箱，读取邮件，根据设定规则对邮件进行分类，比如需要忽略的、通知用户的、自动回复的等&lt;/p&gt;&#xA;&lt;p&gt;自动查看日历并找到合适的时间段，可以根据用户的偏好安排会议时间&lt;/p&gt;&#xA;&lt;p&gt;支持个性化设置，比如基本信息、邮件回复风格、时区和会议偏好等&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/langchain-ai/executive-ai-assistant&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/langchain-ai/executive-ai-assistant&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/executive-ai-assistant.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>面壁的黑科技来了：MiniCPM-o 2.6，多模态互动直接上 iPad！支持视觉、语音和多模态流式交互，性能媲美 GPT-4o-202405，随时随地体验强大 AI。</title>
      <link>https://ansha886.github.io/posts/minicpm-o-2.6/</link>
      <pubDate>Thu, 16 Jan 2025 10:28:48 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/minicpm-o-2.6/</guid>
      <category domain="https://ansha886.github.io/categories/ai/">AI</category>
      <description>&lt;p&gt;MiniCPM-o 2.6是首个支持在iPad等端侧设备进行多模态实时流式交互的模型，具备8B参数量，支持中英双语对话和情感控制，能够实时处理视频和音频流，视觉能力增强，包括OCR和多语言支持。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;酷！面壁开源了其最新模型：MiniCPM-o 2.6，首个支持在 iPad等端侧设备进行多模态实时流式交互的多模态模型，视觉、语音和多模态流式能力说是达到了GPT-4o-202405级别&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;1、总参数量 8B&lt;/p&gt;&#xA;&lt;p&gt;2、支持可配置声音的中英双语语音对话，同时具备情感、语速、风格控制、端到端声音克隆、角色扮演等进阶能力&lt;/p&gt;&#xA;&lt;p&gt;3、能接受连续视频和音频流，进行实时语音交互。在StreamingBench上，超过了GPT-4o-202408和Claude 3.5 Sonnet&lt;/p&gt;&#xA;&lt;p&gt;4、增强了OCR、可信行为、多语言支持和视频理解等视觉能力&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/OpenBMB/MiniCPM-o/tree/main&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/OpenBMB/MiniCPM-o/tree/main&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-1&#34; class=&#34;suffix-invalid suffix-invalid__small suffix-invalid__large&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniCPM-o%202.6-2&#34; class=&#34;suffix-invalid suffix-invalid__small suffix-invalid__large&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MiniMax大招：超长上下文模型强势来袭！最新开源的 MiniMax-Text-01 和 MiniMax-VL-01 模型，支持超长 400 万 token 上下文，AI Agent 领域新标杆。</title>
      <link>https://ansha886.github.io/posts/minimax/</link>
      <pubDate>Thu, 16 Jan 2025 10:26:20 +0800</pubDate>
      <guid>https://ansha886.github.io/posts/minimax/</guid>
      <category domain="https://ansha886.github.io/categories/draft/">Draft</category>
      <description>&lt;p&gt;MiniMax开源了两个新模型，MiniMax-Text-01和MiniMax-VL-01，支持400万token的超长上下文，适合AI Agent领域，能够处理长文档和复杂对话，首次实现Lightning Attention机制，总参数量4560亿。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;MiniMax刚刚开源了两个新模型，基础语言模型 MiniMax-Text-01 和视觉多模态模型 MiniMax-VL-01，超长上下文，支持400万token上下文长度，是其他模型的20-32倍，适合AI Agent领域&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;它可以一次性分析整个长文档，能记住很长的历史对话，适合比如研究分析、法律或文献文档处理、代码理解等等，需要处理大量信息的场景&lt;/p&gt;&#xA;&lt;p&gt;其首次大规模实现了Lightning Attention机制，能够处理更长的上下文，总参数量4560亿，每次推理激活459亿参数&lt;/p&gt;&#xA;&lt;p&gt;github：&lt;a href=&#34;https://github.com/MiniMax-AI/MiniMax-01&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://github.com/MiniMax-AI/MiniMax-01&lt;/a&gt;&#xA;博客：&lt;a href=&#34;https://www.minimaxi.com/en/news/minimax-01-series-2&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.minimaxi.com/en/news/minimax-01-series-2&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax1.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax2.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp&#34; alt=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp&#34; srcset=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp?size=small, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp?size=medium 1.5x, https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp?size=large 2x&#34; data-title=&#34;https://raw.githubusercontent.com/ansha886/blog-images/master/MiniMax3.webp&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
