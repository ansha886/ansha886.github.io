[{"content":"AI ContentCraft 是一款多功能内容创作工具，集文字生成、语音合成和图像生成于一体。它能帮助创作者快速制作故事、播客脚本及相关音视频内容。\n功能 🎯 故事生成：根据主题自动生成短篇故事 📝 脚本转换：将故事转换为标准脚本格式 🎙️ 播客内容：生成播客大纲和对话脚本 🗣️ 语音合成：支持多种声音的文本转语音 🎨 图像生成：生成故事场景的插图 🌐 双语支持：支持中英内容转换 📊 批处理：支持批量生成和下载内容\ngithub地址： https://github.com/nicekate/AI-ContentCraft\n","permalink":"https://ansha886.github.io/posts/ai-contentcraft/","title":"AI-ContentCraft：一站式AI内容创作神器！写文、生声、出图，轻松搞定故事、播客脚本和多媒体内容！"},{"content":"NoteGen是一款强大的AI笔记助手，支持Markdown编辑、AI对话、截图识别和自动整理功能，能够快速捕捉和整理碎片化知识，生成可读笔记。\n一款很不错的AI笔记助手：NoteGen，它提供了强大的记录功能，能快速捕捉和整理碎片化知识，将记录内容整理成一篇笔记\n写作工具内置Markdown编辑器，支持列表大纲、数学公式、图表、流程图、甘特图、时序图、五线谱等\n支持AI机器人对话，可以询问它与记录有关的问题，它输出的内容也可以作为记录保存下来\n支持截图、插图以及文本多种记录方式，截图的话先OCR 识别图片中的文字，再用ChatGPT进行总结\n使用整理功能，自动可以把所有记录整理成一篇可读的笔记\ngithub：https://github.com/codexu/note-gen\n","permalink":"https://ansha886.github.io/posts/notegen/","title":"AI笔记神器NoteGen来了！轻松整理碎片化知识，一键生成高质量笔记！强大的记录功能，帮你快速捕捉和整理内容，告别凌乱，效率倍增！"},{"content":"这是一个关于如何使用Mistral AI、LangChain和Tkinter构建桌面聊天机器人的入门教程，提供了简洁易懂的代码示例，适合快速原型开发，特别以记者助手为例\n基于Mistral AI、LangChain、Tkinter构建的一个桌面聊天机器人教程，教程以记者助手为例，也可以扩展其他用例\n代码简洁易懂，有完整的代码示例，比较实用的一个入门级教程，适合快速原型\n教程：https://medium.com/@mohamedhossam_88384/building-ai-assistant-with-mistral-ai-langchain-and-tkinter-e1e1e5270fe7\n","permalink":"https://ansha886.github.io/posts/mistral-ai-langchain-tkinter/","title":"手把手教你做桌面聊天机器人！Mistral AI+LangChain+Tkinter教程上线！以记者助手为例，轻松上手，还能扩展更多用例，快来试试吧！"},{"content":"OmniThink是一个开源的深度AI写作系统，模拟人类学习和思考过程，提供高知识密度、低冗余的内容生成，支持多种底座模型和可自定义知识来源\n浙大和阿里通义实验室开源的一个深度AI写作系统：OmniThink，它模拟人类学习和思考过程，实现了更深入的AI写作，解决了现在AI内容浅显、重复、非原创的问题\nOmniThink通过迭代扩展，不断扩充知识边界、持续反思、渐进学习的方式模拟人类学习过程\n输出的内容知识密度高，内容冗余少，具备比较强的逻辑性的深度思考能力\n支持多种底座模型，可自定义知识来源，可调整生成策略，不过生成质量依赖底座模型质量\n项目主页：https://zjunlp.github.io/project/OmniThink/ github：https://github.com/zjunlp/OmniThink\n","permalink":"https://ansha886.github.io/posts/omnithink/","title":"阿里和浙大通义实验室联手推出：OmniThink，让AI写作更“走心”！模拟人类学习和思考，深入解决内容浅显、重复、非原创的问题，AI写作迈入新高度。"},{"content":"ReaderLM-v2是一个1.5B的小模型，专门用于将HTML转换为Markdown和JSON，支持复杂格式和29种语言，适合批量处理网页和自动化数据提取。性能超过多个大型模型。\n一款专门用于将HTML转为Markdown和JSON格式的小模型：ReaderLM-v2，只有1.5B，性能超过了Qwen2.5-32B、Gemini2-flash、GPT-4o-2024-08-06等\n1、可以处理长文本，支持复杂格式，比如表格、嵌套列表、LaTeX公式等\n2、稳定性比较好，没有重复或循环的问题\n3、支持29种语言，包括英语、中文、日语、韩语、法语、西班牙语、葡萄牙语、德语、意大利语、俄语、越南语、泰语、阿拉伯语等\n适合需要批量处理网页或自动化网页数据提取的场景\nHF：https://huggingface.co/jinaai/ReaderLM-v2\n","permalink":"https://ansha886.github.io/posts/readerlm-v2/","title":"一款专门用于将HTML转为Markdown和JSON格式的小模型：ReaderLM-v2，只有1.5B，性能超过了Qwen2.5-32B、Gemini2-flash、GPT-4o-2024-08-06等"},{"content":"RLLoggingBoard是一款开源工具，可以实时可视化RLHF训练过程中的数据，帮助分析训练效果并定位潜在问题。通过监控token概率和response reward分布，用户可以更直观地了解训练动态。\n酷！一款可以对RLHF训练过程可视化的工具：RLLoggingBoard，可以实时显示AI模型训练时的各种数据，分析训练效果\n可以更直观看到RL训练过程，比如，token概率会随着训练升高或降低情况、response reward分布随着训练的变化情况等\n当训练不符合预期时，通过监控token粒度的指标来定位可能的问题\ngithub：https://github.com/HarderThenHarder/RLLoggingBoard\n","permalink":"https://ansha886.github.io/posts/rlloggingboard/","title":"酷！一款可以对RLHF训练过程可视化的工具：RLLoggingBoard，可以实时显示AI模型训练时的各种数据，分析训练效果"},{"content":"OpenScholar是一款AI工具，帮助用户阅读和理解科研论文，自动查找相关论文并以通俗易懂的方式呈现内容，支持标准RAG流程，具备自反思生成能力，解决科研论文数量庞大的问题。\n一款辅助阅读和理解科研论文的AI工具，一个科研助手：OpenScholar\n它可以基于提问自动查找相关的论文，并把论文内容消化后用通俗易懂的方式回，且会标注信息来源，解决每年新发表的论文太多看不过来的问题\n支持标准RAG流程，包含检索器+重排序器管道，具备自反思生成能力\ngithub：https://github.com/AkariAsai/OpenScholar\n","permalink":"https://ansha886.github.io/posts/openscholar/","title":"一款辅助阅读和理解科研论文的AI工具，一个科研助手：OpenScholar"},{"content":"酷，中国科学技术大学和通义实验室出的一款可以在消费级设备上实时动画生成的系统：RAIN，且能生成无限长视频动画，流畅稳定性，准确性和一致性非常好\n酷，中国科学技术大学和通义实验室出的一款可以在消费级设备上实时动画生成的系统：RAIN，且能生成无限长视频动画，流畅稳定性，准确性和一致性非常好\n支持实时转换表情以及头部动作\n主页：https://pscgylotti.github.io/pages/RAIN/ github（代码陆续放出）：https://github.com/Pscgylotti/RAIN\n","permalink":"https://ansha886.github.io/posts/rain/","title":"国科大×通义实验室：RAIN系统实现实时动画生成！消费级设备就能运行，无限长视频动画生成，流畅又精准，动画领域的新标杆！"},{"content":"OmAgent是一个开源工具，支持多模态数据处理，整合多种模型，提供图的工作流编排和多种思维推理方式，能够快速开发智能AI助手。\n一款可以快速开发\u0026quot;会看会听会说\u0026quot;的AI助手的工具：OmAgent\n原生支持多模态数据，文本、图像、视频和音频，能整合各种模型，VLM、计算机视觉模型和实时API，可以构建能处理多种信息类型的智能体\n提供基于图的工作流编排引擎和多种内存类型，实现上下文推理\n包含多种思维推理方式，ReAct、CoT、SC-Cot等，能处理复杂任务\ngithub：https://github.com/om-ai-lab/OmAgent\n","permalink":"https://ansha886.github.io/posts/omagent/","title":"OmAgent来了：快速打造“能看会听还会说”的AI助手！一个专为开发智能助手的工具，让AI开发简单又高效。"},{"content":"智谱发布了GLM-Realtime，一个全新的端到端多模态模型，支持近乎实时的视频理解、语音交互、清唱功能以及长达2分钟的记忆和Function Call功能，现阶段可通过API免费调用。\n酷，智谱刚刚发布了其全新端到端多模态模型：GLM-Realtime，近乎实时的视频理解与语音交互，融入了清唱功能，支持长达2分钟的记忆及Function Call功能\nGLM-Realtime在实现完全实时交互的基础上，进一步支持Function Call功能，这使其不仅能够依靠自身知识和能力，还能灵活调用外部知识和工具，拓展更广泛的应用场景\nAPI： http://bigmodel.cn，现阶段可以免费调用\n","permalink":"https://ansha886.github.io/posts/glm-realtime/","title":"智谱新作：GLM-Realtime，多模态互动像开挂一样顺滑！实时视频理解、语音交互，还有清唱功能和长达2分钟的记忆，Function Call也安排上了！"},{"content":"微软开源了MatterGen，一个AI驱动的材料生成模型，可以根据需求描述生成具有多种属性的新材料，开启了材料设计的新范式。\n厉害，微软刚刚开源了一个用AI设计新材料的模型：MatterGen，它可以根据需求描述，直接生成新材料\n它可以生成具有化学、机械、电子或磁性属性的材料，或多种特性的组合\nMatterGen开启了材料生成新范式，通过生成式AI辅助材料设计，可以更高效地探索材料，突破已知材料的限制\n博客：https://www.microsoft.com/en-us/research/blog/mattergen-a-new-paradigm-of-materials-design-with-generative-ai/\n代码：https://github.com/microsoft/mattergen\n","permalink":"https://ansha886.github.io/posts/mattergen/","title":"微软又放大招！AI设计新材料，MatterGen帮你一键生成！用需求描述就能设计新材料，这款开源模型让材料研发更高效、更智能。"},{"content":"executive-ai-assistant是一款AI助手，能够监控工作邮件、自动回复、安排日程和管理日历，支持个性化设置和会议时间的智能安排。\n一个可以帮你处理工作邮件和日程的AI助手，一个行政助手：executive-ai-assistant，可以邮件监控和自动回复，进行日程安排和日历管理\n可以监控指定邮箱，读取邮件，根据设定规则对邮件进行分类，比如需要忽略的、通知用户的、自动回复的等\n自动查看日历并找到合适的时间段，可以根据用户的偏好安排会议时间\n支持个性化设置，比如基本信息、邮件回复风格、时区和会议偏好等\ngithub：https://github.com/langchain-ai/executive-ai-assistant\n","permalink":"https://ansha886.github.io/posts/executive-ai-assistant/","title":"AI行政助手出场：帮你搞定邮件、日程和日历！executive-ai-assistant，这款AI工具监控邮件、自动回复、安排日程，职场人的效率神器。"},{"content":"MiniCPM-o 2.6是首个支持在iPad等端侧设备进行多模态实时流式交互的模型，具备8B参数量，支持中英双语对话和情感控制，能够实时处理视频和音频流，视觉能力增强，包括OCR和多语言支持。\n酷！面壁开源了其最新模型：MiniCPM-o 2.6，首个支持在 iPad等端侧设备进行多模态实时流式交互的多模态模型，视觉、语音和多模态流式能力说是达到了GPT-4o-202405级别\n1、总参数量 8B\n2、支持可配置声音的中英双语语音对话，同时具备情感、语速、风格控制、端到端声音克隆、角色扮演等进阶能力\n3、能接受连续视频和音频流，进行实时语音交互。在StreamingBench上，超过了GPT-4o-202408和Claude 3.5 Sonnet\n4、增强了OCR、可信行为、多语言支持和视频理解等视觉能力\ngithub：https://github.com/OpenBMB/MiniCPM-o/tree/main\n","permalink":"https://ansha886.github.io/posts/minicpm-o-2.6/","title":"面壁的黑科技来了：MiniCPM-o 2.6，多模态互动直接上 iPad！支持视觉、语音和多模态流式交互，性能媲美 GPT-4o-202405，随时随地体验强大 AI。"},{"content":"MiniMax开源了两个新模型，MiniMax-Text-01和MiniMax-VL-01，支持400万token的超长上下文，适合AI Agent领域，能够处理长文档和复杂对话，首次实现Lightning Attention机制，总参数量4560亿。\nMiniMax刚刚开源了两个新模型，基础语言模型 MiniMax-Text-01 和视觉多模态模型 MiniMax-VL-01，超长上下文，支持400万token上下文长度，是其他模型的20-32倍，适合AI Agent领域\n它可以一次性分析整个长文档，能记住很长的历史对话，适合比如研究分析、法律或文献文档处理、代码理解等等，需要处理大量信息的场景\n其首次大规模实现了Lightning Attention机制，能够处理更长的上下文，总参数量4560亿，每次推理激活459亿参数\ngithub：https://github.com/MiniMax-AI/MiniMax-01 博客：https://www.minimaxi.com/en/news/minimax-01-series-2\n","permalink":"https://ansha886.github.io/posts/minimax/","title":"MiniMax大招：超长上下文模型强势来袭！最新开源的 MiniMax-Text-01 和 MiniMax-VL-01 模型，支持超长 400 万 token 上下文，AI Agent 领域新标杆。"},{"content":"Transformer²是一个自适应框架，能够实时调整LLM以适应新任务，无需传统微调，提升灵活性和效率。通过快速诊断任务类型和选择性调整参数，解决了反复训练的问题。\n一个自适应框架：Transformer²，它能即时应变，实时调整LLM适应没见过的任务，无需传统的微调过程，提升LLM在处理新任务时的灵活性和效率\n实时学习适应，碰到新任务能立即调整，减少了反复训练的问题\n选择性调整，只调整必要的参数\n两步处理机制，第一步快速诊断任务类型，第二步根据任务调整处理方式\ngithub：https://github.com/SakanaAI/self-adaptive-llms\n","permalink":"https://ansha886.github.io/posts/transformer/","title":"LLM即插即用神器：Transformer²，让模型适应新任务快人一步！告别传统微调，这个自适应框架实时调整，让大模型更灵活、更高效地应对新挑战。"},{"content":"社交媒体自动化助手social-media-agent可以根据给定的URL自动生成Twitter和LinkedIn的帖子，支持内容审核和修改，兼容GitHub、YouTube等源内容，并可与Slack集成。\n一款社交媒体自动化助手：social-media-agent，给它一个URL，它可以自动给该内容生成社交媒体平台的帖子，可以人工介入审核修改\n自动读取内容，生成文案+配图，可以自定义文案风格\n支持生成Twitter和LinkedIn的帖子\n支持处理比如GitHub、Twitter、YouTube等源内容，支持与Slack集成\ngithub：https://github.com/langchain-ai/social-media-agent\n","permalink":"https://ansha886.github.io/posts/social-media-agent/","title":"社交媒体助手上线：只需给它一个URL，就能帮你搞定平台帖子！一款名叫 social-media-agent 的工具，自动生成社交媒体内容，还能手动调整，轻松提升效率。"},{"content":"WrenAI是一款AI数据交互工具，支持自然语言提问并生成SQL查询，提供数据可视化和报表功能，适合多语言用户，支持无缝工作流导出CSV或JSON格式。\n一款非常棒的AI数据交互工具：WrenAI，你可以用自然语言提问，它能理解你的意图并生成SQL查询，还能把数据转成图表、表格、报表和BI等，非常适合数据团队\n它是一个端到端的解决方案，不只是SQL生成，它提供了从提问到数据可视化、报表生成一套完整流程\n支持英语、德语、西班牙语、法语、日语、韩语、葡萄牙语、中文等多语言\n支持语义理解，它能理解数据背后的语义和业务逻辑，生成的SQL查询更精准\n提供无缝端到端的工作流，你可以输出CSV或JSON格式导入到Excel或Google表格中进一步使用\ngithub：https://github.com/Canner/WrenAI\n","permalink":"https://ansha886.github.io/posts/wrenai/","title":"WrenAI：用聊天的方式搞定SQL，还能秒变图表！数据团队的绝佳拍档，问一句话，结果全出来"},{"content":"Ingredients是一个开源的视频生成项目，能够输入多张人物图像和文字描述，生成包含这些人物的视频，效果自然流畅，支持同时处理多个人物图像。\n酷，一个多身份定制化视频生成项目：Ingredients，输入多张人物图像+文字描述，它可以输出包含这些人物的视频\n可以同时处理多个人物图像 每个人物的身份特征保持不变 生成效果相对自然流畅\ngithub：https://github.com/feizc/Ingredients\n","permalink":"https://ansha886.github.io/posts/ingredients/","title":"多身份视频制作神器 Ingredients，轻松把想法做成视频一键生成你想要的人物视频，酷炫到不行"},{"content":"Riona-AI-Agent是一款社交媒体机器人，可以自动管理多个社交账号，自动点赞、评论和回复粉丝评论，支持Instagram自动化，Twitter和GitHub的功能正在开发中。\n自媒体神器，一款社交媒体机器人：Riona-AI-Agent，可以自动点赞评论，自动回复粉丝评论\n可以同时管理多个社交账号 自动保持登录状态 贴子内容自动生成 可以完成Instagram的自动化，自动登录、点赞、评论，Twitter、GitHub的自动化正在开发\ngithub：https://github.com/David-patrick-chuks/Riona-AI-Agent\n","permalink":"https://ansha886.github.io/posts/riona-ai-agent/","title":"做自媒体必备！Riona-AI-Agent，自动化运营的小能手点赞、评论、回复全搞定，省时省力又省心"},{"content":"英伟达开源的Sana模型能够生成4096 × 4096分辨率的图像，性能与Flux-12B相当，参数量仅为其1/20，速度快100倍，适合在16GB显卡上运行。\n英伟达开源的文生图模型：Sana，能生成4096 × 4096分辨率的图像，Sana0.6B性能上和Flux-12B也具备竞争力，参数量只有其 1/20，速度快100倍\n可以在 16GB 的显卡上运行，不到一秒钟即可生成一张1024x1024分辨率的图像\ngithub：https://github.com/NVlabs/Sana\n","permalink":"https://ansha886.github.io/posts/sana/","title":"英伟达 Sana：速度快100倍，生成超清图像的高手！分辨率 4096 × 4096，性能吊打大模型，效率直接拉满"},{"content":"StructLDM是一个开源项目，能够生成完整的3D人体模型，支持不同姿势和视角的生成，以及服装和体型的编辑修改，允许局部试穿和身份交换等功能。\n一个3D人体模型生成项目：StructLDM，它可以生成完整的3D人体，还支持部分编辑修改，比如更换服装、改变姿势等\n1、支持生成不同姿势和视角的3D人体模型\n2、视角一致性比较好，生成的3D人体模型从不同视角看能保持一致，没有明显的瑕疵情况\n3、支持不同程度的可控生成以及编辑，可以指定模型姿势、视角以及模型的体型、身材比例等\n4、还可以进行编辑，比如局部的服装编辑、试穿、身份交换等，或者是组合生成，比如把一个模型的头和另一个的身体组合成新的模型\ngithub：https://github.com/TaoHuUMD/StructLDM\n","permalink":"https://ansha886.github.io/posts/structldm/","title":"超强3D人体生成工具 StructLDM，随心换装、改姿势！想怎么调整就怎么调整，3D建模从此轻松搞定"},{"content":"阿里通义实验室推出的MinMo模型支持自然的全双工语音交互，能够控制生成语音的情感和方言，表现出色于多语言识别和翻译等任务，代码和模型即将发布。\n阿里通义实验室最新出的一款可无缝语音交互的多模态模型：MinMo，语音交互上比较自然，支持不同的语气或方言回应\n支持全双工语音交互，用户和系统可以同时进行对话，语音到文本的延迟约为100毫秒，全双工延迟理论上约600毫秒，实际约800毫秒\n可以控制生成语音的情感、方言和说话风格，甚至声音模仿\nMinMo在语音对话、多语言语音识别、多语言语音翻译、情感识别、说话人分析和音频事件分析等多个语音相关任务上表现出色\n主页：https://funaudiollm.github.io/minmo/\n代码和模型即将发布\n","permalink":"https://ansha886.github.io/posts/minmo/","title":"阿里通义的新作 MinMo，语音交互就像聊天一样自然, 不管是普通话还是方言，回应都无缝又贴心"},{"content":"英伟达开源的nv-ingest工具能够高效处理PDF、Word、PPT和图像等复杂文档，支持同时处理多个文档并提取页面上的表格、图表、图像和文本等内容类型。\n英伟达开源的一款智能文档信息提取及结构化工具：nv-ingest，能高效处理大规模的PDF、Word、PPT以及图像等复杂的文档，并结构化输出\n它可以同时处理多个文档，并把每个文档分成独立的页面，能识别页面上表格、图表、图像以及文本等不同的内容类型，分别提取出来\ngithub：https://github.com/NVIDIA/nv-ingest\n","permalink":"https://ansha886.github.io/posts/nv-ingest/","title":"英伟达又出神器！nv-ingest，秒处理各种文档，结构化输出so easy！PDF、Word、PPT、图像通通搞定，高效到离谱！"},{"content":"基于OpenAI实时API和WebRTC的AI语音助手支持多种语言的实时语音转录对话，并可集成工具扩展应用能力，如获取时间和访问网站\n一款基于WebRTC的AI语音助手：openai-realtime-api-nextjs，实时语音对话\n用OpenAI实时API和WebRTC实现实时语音转录对话，支持英语、西班牙语、法语、中文等多种语言\n支持工具调用， 可以集成各种客户端工具扩展应用能力，比如获取当前时间、访问网站、复制文本等\ngithub：https://github.com/cameronking4/openai-realtime-api-nextjs\n","permalink":"https://ansha886.github.io/posts/openai-realtime-api-nextjs/","title":"基于WebRTC的AI语音助手openai-realtime-api-nextjs 打造实时语音对话新体验"},{"content":"lipsync-1.9测试版是一款高质量的唇形同步模型，支持零样本学习，无需训练数据，可在真实视频、动画和AI生成的视频中自然生成和编辑语音。\nsync最新出的其唇形同步模型lipsync-1.9测试版，效果看起来非常不错，唇形同步的质量很高\n零样本学习，无需任何训练数据， 可以在真实视频、动画以及AI生成的视频中，无缝生成比较自然的语音，还可以编辑语音\n地址：https://sync.so/\n","permalink":"https://ansha886.github.io/posts/lipsync-1.9/","title":"唇形同步模型lipsync-1.9测试版发布 实现高质量唇形同步体验"},{"content":"英伟达开源的nv-ingest工具能够高效处理PDF、Word、PPT和图像等复杂文档，支持同时处理多个文档并提取页面上的表格、图表、图像和文本等内容类型。\n英伟达开源的一款智能文档信息提取及结构化工具：nv-ingest，能高效处理大规模的PDF、Word、PPT以及图像等复杂的文档，并结构化输出\n它可以同时处理多个文档，并把每个文档分成独立的页面，能识别页面上表格、图表、图像以及文本等不同的内容类型，分别提取出来\ngithub：https://github.com/NVIDIA/nv-ingest\n","permalink":"https://ansha886.github.io/posts/nv-ingest/","title":"英伟达开源智能文档处理工具nv-ingest 高效提取和结构化复杂文档信息"},{"content":"Ingredients是一个开源的视频生成项目，能够输入多张人物图像和文字描述，生成包含这些人物的视频，效果自然流畅，支持同时处理多个人物图像。\n酷，一个多身份定制化视频生成项目：Ingredients，输入多张人物图像+文字描述，它可以输出包含这些人物的视频\n可以同时处理多个人物图像 每个人物的身份特征保持不变 生成效果相对自然流畅\ngithub：https://github.com/feizc/Ingredients\n","permalink":"https://ansha886.github.io/posts/ingredients/","title":"多身份定制化视频生成项目Ingredients解析 输入图像和文字即可生成个性化视频"},{"content":"STAR是一款开源工具，能在提高视频分辨率的同时保持时间一致性和细节完整性，智能调整清晰度，解决画面连续性和真实感问题。\n南京大学、字节等开源的一款提高视频清晰度的工具：STAR，它能在提高分辨率的同时，保持视频时间一致性和细节完整性，没有细节丢失、运动不自然的问题\n它可以根据视频的不同部分，智能调整清晰度力度，以保证整体的清晰度，又避免过度锐化导致画面不自然\n它用文本到视频模型学习到的视觉特征和时空信息来增强超分辨率过程，解决了画面连续性，使视频前后帧之间流畅，不会跳动，以及视频真实感的问题\ngithub：https://github.com/NJU-PCALab/STAR\n","permalink":"https://ansha886.github.io/posts/star/","title":"STAR：南京大学与字节跳动开源的视频清晰度提升工具，兼顾细节与时间一致性"},{"content":"一键搜索企业信息，一款企业信息研究助手：Company Researcher，输入公司网址，自动收集展示该公司的综合信息 信息来源包括网站子页面、LinkedIn数据、财务信息，新闻报道、维基百科信息、社交媒体Twitter、YouTube、TikTok、Reddit、GitHub等\n一键搜索企业信息，一款企业信息研究助手：Company Researcher，输入公司网址，自动收集展示该公司的综合信息\n信息来源包括网站子页面、LinkedIn数据、财务信息，新闻报道、维基百科信息、社交媒体Twitter、YouTube、TikTok、Reddit、GitHub等\ngithub：https://github.com/exa-labs/company-researcher\n","permalink":"https://ansha886.github.io/posts/company-researcher/","title":"Company Researcher：一键搜索企业信息的研究助手，轻松获取公司综合资料"},{"content":"Google Labs推出的AI图像生成工具Whisk，可以通过输入角色、场景和风格的三张图像，自动生成新图像，基于Gemini生成详细描述并使用Google Imagen 3模型进行图像生成，但目前存在使用国家限制。\nGoogle Labs最新推出的AI图像生成工具非常酷，Whisk，给它角色、场景、风格三张图像，它可以自动构图生成非常棒的新图像\n它基于Gemini自动为给定的图像生成详细描述，再将描述输入到Google Imagen 3图像生成模型里生成图像\n不过目前有使用国家限制 使用地址：https://labs.google/fx/tools/whisk/unsupported-country\n","permalink":"https://ansha886.github.io/posts/whisk/","title":"Whisk：Google Labs推出的AI图像生成工具，融合角色、场景和风格自动生成创意图像"},{"content":"首款开源AI会议助手amurex提供实时建议、自动记录会议内容、生成总结和邮件跟进，涵盖全流程会议辅助\n酷！首款开源的AI会议助手：amurex，它能提供实时会议建议、自动记录会议内容生成总结、会议回顾、一键生成和发送邮件跟进会议事项\n它涵盖了从会议进行中的实时建议，到会议后的总结和后续跟进，提供全流程会议辅助\ngithub：https://github.com/thepersonalaicompany/amurex\n","permalink":"https://ansha886.github.io/posts/amurex/","title":"Amurex：首款开源AI会议助手，支持实时建议、会议总结和自动化跟进任务"},{"content":"Lobe Vidol是一个开源项目，允许用户创建互动式虚拟偶像，支持文字聊天、语音视频对话和角色跳舞，用户可以上传3D模型或使用现成角色模型并自定义动作和反应。\n一个互动式虚拟偶像的构建项目：Lobe Vidol，可以进行文字聊天、语音视频对话，支持角色跳舞\n可以上传3D模型或使用现成的角色模型创建虚拟角色，可以自定义角色的动作和反应\n支持更换舞台和背景，点击角色互动\ngithub：https://github.com/lobehub/lobe-vidol\n","permalink":"https://ansha886.github.io/posts/lobe-vidol/","title":"Lobe Vidol：互动式虚拟偶像构建项目，支持文字聊天、语音视频对话及角色跳舞"},{"content":"字节跳动开源的一个唇形同步项目：LatentSync，是一个端到端的唇形同步框架，效果比较自然，连贯性非常好\n字节跳动开源的一个唇形同步项目：LatentSync，是一个端到端的唇形同步框架，效果比较自然，连贯性非常好\ngithub：https://github.com/bytedance/LatentSync\n","permalink":"https://ansha886.github.io/posts/latentsync/","title":"LatentSync：字节跳动开源的端到端自然唇形同步框架"},{"content":"Open Deep Research是一款开源AI研究助手，支持自动化研究、报告生成及网页内容提取分析，具备时间过滤搜索功能和多种格式导出选项。\n一款AI研究助手：Open Deep Research，基于主题自动化研究并生成报告，Gemini Deep Research的开源替代方案\n搜索、研究、写作自动化，支持网页内容的提取和分析，可以导出PDF、Word、Text多种格式\n支持带有时间过滤的网页搜索功能，可调整搜索范围和数量，自定义报告风格，自定义提示词引导研究方向等\ngithub：https://github.com/btahir/open-deep-research\n","permalink":"https://ansha886.github.io/posts/open-deep-research/","title":"Open Deep Research：自动化主题研究与报告生成的开源AI助手"},{"content":"browser-use-webui是一款增强功能的浏览器AI助手，支持多种LLM，提供Web界面，避免重复登录，支持高清屏幕录制和提示词优化。\n基于Browser Use的一款浏览器AI助手：browser-use-webui，在原来的基础上做了功能增强\n提供了一个Web 界面，支持多种browser-use功能\n扩展了对DeepSeek、Gemini、OpenAI、Azure OpenAI、Anthropic、Ollama等LLM的支持\n可以使用自己的浏览器，避免重复登录认证问题，支持高清屏幕录制，具备提示词优化能力\ngithub：https://github.com/warmshao/browser-use-webui\n","permalink":"https://ansha886.github.io/posts/browser-use-webui/","title":"Browser-Use-WebUI：功能增强版的浏览器AI助手"},{"content":"ImBD是一款开源AI文章检测工具，能够高效检测文章是否经过AI修改，支持检测纯AI生成和润色、改写、扩写的文本，准确率高达99.96%。其性能在检测不同版本的AI生成文本时显著提升，适合用于论文和稿件的原创性检测。\n酷，多高校开源的一个AI文章检测工具：ImBD(Imitate Before Detect)，可以检测文章是否被AI修改过，能检测纯AI生成的，还能检测被AI润色、改写、扩写的，准确率高\n用来检测论文、稿件原创性就非常轻松，它仅使用1000个样本和5分钟的SPO就超过了商业的GPT-Zero\n检测开源LLM修改文本上提高了13%，检测GPT-3.5和GPT-4o修改的文本上，性能提高了5%和19%\n支持像改写、扩写、润色都可以，纯AI生成的检测率能到99.96%，改写87.39%，扩写97.58%，润色97.07%\ngithub：https://github.com/Jiaqi-Chen-00/ImBD Demo：https://ai-detector.fenz.ai/ai-detector\n","permalink":"https://ansha886.github.io/posts/imbd/","title":"ImBD：一款高准确率的AI文章检测工具，支持检测AI生成、润色、改写与扩写内容"},{"content":"AnyDressing是一个多服装虚拟试穿项目，支持同时试穿多件衣服，处理复杂组合，适用于多种场景，且可与其他AI工具配合使用，具备强大的定制性和个性化调整功能。\n酷，字节和清华的一款多服装虚拟试穿项目：AnyDressing，它支持同时试穿多件衣服，能处理复杂服装组合，看起来细节保持和衣服贴合度比较好\n1、比如试穿上衣+裤子+外套，一次性完成，可定制性强， 能够处理多种服装组合和个性化文本提示\n2、适用于各种场景，支持现实风格生成也支持动漫风\n3、可以和其他AI工具配合使用(ControlNet, LoRA等)，支持文字描述来调整生成效果，比如调整衣服的风格、人物表情等等\ngithub：https://github.com/Crayon-Shinchan/AnyDressing 项目：https://crayon-shinchan.github.io/AnyDressing/\n","permalink":"https://ansha886.github.io/posts/anydressing/","title":"多服装虚拟试穿项目：AnyDressing，支持复杂服装组合与高细节贴合"},{"content":"ai-no-jimaku-gumi是一款开源AI工具，能够自动从视频音频中提取语音生成字幕，并支持多种语言翻译，主要输出SRT格式，允许自定义参数设置。\n一款视频字幕AI工具：ai-no-jimaku-gumi，自动将视频转换成字幕并翻译成多种语言\n从视频音频中提取语音自动生成字幕 支持包括但不限于英语、日语、中文等多语言翻译\n目前主要支持SRT字幕格式输出 支持自定义参数\ngithub：https://github.com/Inokinoki/ai-no-jimaku-gumi\n","permalink":"https://ansha886.github.io/posts/ai-no-jimaku-gumi/","title":"AI 视频字幕工具：ai-no-jimaku-gumi，可自动生成多语言翻译字幕"},{"content":"Mainframe-Orchestra是一个轻量级的开源AI智能体构建框架，支持多智能体团队和复杂工作流程，具备角色专业化、模块化设计和智能编排机制。\n一款轻量级的开源AI智能体构建框架：Mainframe-Orchestra，可构建基于LLM任务流程的多智能体团队，支持复杂的工作流程\n1、角色专业化设计，每个智能体都有明确的身份定位，配备专门的工具和技能 2、模块化设计，可以自由组合不同AI及工具，支持多LLM，内置工具集 3、智能编排机制，智能体可以同时是执行者和指挥者，支持动态任务分解\ngithub：https://github.com/mainframecomputer/orchestra\n","permalink":"https://ansha886.github.io/posts/%E4%B8%80%E6%AC%BE%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9A%84%E5%BC%80%E6%BA%90ai%E6%99%BA%E8%83%BD%E4%BD%93%E6%9E%84%E5%BB%BA%E6%A1%86%E6%9E%B6mainframe-orchestra%E5%8F%AF%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8Ellm%E4%BB%BB%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%9A%84%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%9B%A2%E9%98%9F%E6%94%AF%E6%8C%81%E5%A4%8D%E6%9D%82%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/","title":"一款轻量级的开源AI智能体构建框架：Mainframe-Orchestra，可构建基于LLM任务流程的多智能体团队，支持复杂的工作流程"},{"content":"ExtractThinker是一款开源的智能文档处理工具，支持PDF、图片和表格等多种格式，具有自定义提取规则、自动分类和异步批量处理功能。\n一款基于LLM的智能文档处理工具：ExtractThinker\n支持PDF、图片、表格等多种格式，可以自定义提取规则 自动分类，自动判断文件类型，根据不同的类型提取不同的信息 支持异步处理大文档，批量处理多个文档\ngithub：https://github.com/enoch3712/ExtractThinker\n","permalink":"https://ansha886.github.io/posts/extractthinker/","title":"一款基于LLM的智能文档处理工具：ExtractThinker"},{"content":"一款优秀的长故事可视化工具——Story-Adapter，它能够自动生成100帧的漫画或动画分镜图，并且在故事的语义一致性方面表现出色。\n一款不错的长故事可视化工具：Story-Adapter，可以自动生成100帧漫画或动画的分镜图，故事的语义一致性比较好\n不需要额外训练可以直接用 画面连贯性保持的可以，图片间逻辑清晰，人物场景也能保持一致\ngithub：https://github.com/jwmao1/story-adapter\n","permalink":"https://ansha886.github.io/posts/story-adapter/","title":"一款优秀的长故事可视化工具——Story-Adapter，它能够自动生成100帧的漫画或动画分镜图，并且在故事的语义一致性方面表现出色。"},{"content":"Pathway 是一款专为实时数据处理及 AI 应用场景打造的数据处理工具，支持实时数据处理、分析以及 LLM 和 RAG 数据的高效管理\n一款适合需要实时数据处理或构建AI应用场景的数据处理工具：Pathway，可以处理实时数据、分析、LLM和RAG数据\n能处理实时数据流也能处理历史数据，一套代码用于两种场景 底层用Rust开发，速度快，支持多线程和分布式处理 集成能力强可以连接多种数据源，支持主流LLM及常用AI工具\ngithub：https://github.com/pathwaycom/pathway\n","permalink":"https://ansha886.github.io/posts/pathway/","title":"Pathway 是一款专为实时数据处理及 AI 应用场景打造的数据处理工具，支持实时数据处理、分析以及 LLM 和 RAG 数据的高效管理"},{"content":"核心逻辑约一千行代码，轻量功能完整，支持创建CodeAgent和ToolCallingAgent两种类型的agent\nHugging Face开源的一款轻量级的agent构建工具：Smolagents，核心逻辑约一千行代码\n轻量功能完整，支持创建CodeAgent和ToolCallingAgent两种类型的agent\ngithub：https://github.com/huggingface/agents\n","permalink":"https://ansha886.github.io/posts/smolagents/","title":"Hugging Face开源的一款轻量级的agent构建工具：Smolagents，核心逻辑约一千行代码"},{"content":"短视频内容制作神器！北大等高校开源的一个可控制的人物图像动画视频项目：DisPose，人物特征、服装细节等细节保持的很好，动作过度看起来比较自然流畅\n短视频内容制作神器！北大等高校开源的一个可控制的人物图像动画视频项目：DisPose，人物特征、服装细节等细节保持的很好，动作过度看起来比较自然流畅\n输入要求比较简单，参考照片+骨骼动作数据即可\n可作为一个模块化的工具，集成到现有动画生成模型中，不需要对现有模型进行大规模修改\n泛化能力强，参考照片人物和视频里人物体型不一样，也可生成自然的动画\ngithub：https://github.com/lihxxx/DisPose\n","permalink":"https://ansha886.github.io/posts/dispose/","title":"短视频内容制作神器！北大等高校开源的一个可控制的人物图像动画视频项目：DisPose，人物特征、服装细节等细节保持的很好，动作过度看起来比较自然流畅"},{"content":"一个用Gemini多模态实时API和WebRTC结合构建的语音AI应用示例：gemini-webrtc-web-simple 低延迟、声音质量更好，对于需要处理实时媒体流的应用比较友好\n一个用Gemini多模态实时API和WebRTC结合构建的语音AI应用示例：gemini-webrtc-web-simple\n低延迟、声音质量更好，对于需要处理实时媒体流的应用比较友好\ngithub：https://github.com/pipecat-ai/gemini-webrtc-web-simple\nconst rtviClient = new RTVIClient({ transport, params: { baseUrl: \u0026ldquo;http://localhost:7860/\u0026rdquo;, }, enableMic: true, enableCam: false, timeout: 30 * 1000, });\n","permalink":"https://ansha886.github.io/posts/gemini-webrtc-web-simple/","title":"一个用Gemini多模态实时API和WebRTC结合构建的语音AI应用示例：gemini-webrtc-web-simple"},{"content":"IdentityRAG 是一款集成身份识别功能的 RAG 系统，专为企业客户管理设计。它结合了客户数据管理、身份识别与 AI 聊天功能，能够针对特定客户提供准确且具有上下文感知的回答，为企业提升客户管理效率提供了智能化支持。\n一个集成了身份识别功能的RAG系统：IdentityRAG，它可以针对特定客户提供准确且具有上下文感知的回答，把客户数据管理、身份识别、AI聊天结合到一起了，适合企业做客户管理使用\n支持连接不同的数据源，数据库或者文件，把分散的客户信息汇总起来形成完整的客户档案\n它可以识别同一个人的不同记录，会自动合并相关信息\ngithub：https://github.com/tilotech/identity-rag-customer-insights-chatbot\n","permalink":"https://ansha886.github.io/posts/identityrag/","title":"IdentityRAG 是一款集成身份识别功能的 RAG 系统，专为企业客户管理设计。它结合了客户数据管理、身份识别与 AI 聊天功能，能够针对特定客户提供准确且具有上下文感知的回答，为企业提升客户管理效率提供了智能化支持。"},{"content":"清华和腾讯也开源了一款图像自动上色AI模型：ColorFlow，可以给黑白图像序列上色，特点是能保持角色特征的一致性\n清华和腾讯也开源了一款图像自动上色AI模型：ColorFlow，可以给黑白图像序列上色，特点是能保持角色特征的一致性\n用检索增强的方式上色\n人物发色、服装等元素的颜色可以保持很好的一致性\ngithub：https://github.com/TencentARC/ColorFlow\n","permalink":"https://ansha886.github.io/posts/colorflow/","title":"清华和腾讯也开源了一款图像自动上色AI模型：ColorFlow，可以给黑白图像序列上色，特点是能保持角色特征的一致性"},{"content":"通过Composio，轻松为你的AI智能体集成高质量工具和服务，无需操心认证、准确性和可靠性——一行代码即可搞定！\n🔥 核心功能\n• 100+ 强大工具支持，涵盖多个领域：\n• 软件类：GitHub、Notion、Gmail、Slack、HubSpot、Salesforce等90+工具。\n• 操作系统类：模拟点击、输入文本、剪贴板操作等。\n• 浏览器类：智能搜索、截图、下载、上传等功能。\n• 搜索类：Google Search、Perplexity、Tavily、Exa等多种搜索引擎集成。\n• 开发工具：Ngrok、数据库、Redis、Vercel、Git等。\n• RAG功能：即时检索增强生成（RAG），支持任意类型数据处理。\n• 框架兼容性强：与主流AI智能体框架无缝集成：\n• OpenAI、Groq（兼容OpenAI API）、Claude、LlamaIndex、LangChain、CrewAI、Autogen、Gemini、Julep等。\n• 统一授权管理：内置六大认证协议，轻松实现授权：\n• 支持Access Token、Refresh Token、OAuth、API Key、JWT等，简化接入流程。\n• 高准确性：优化工具设计，提升40%+ 智能体工具调用的准确率。\n• 可嵌入 \u0026amp; 可扩展：\n• 可嵌入：支持后端集成，统一管理认证和工具，提供稳定一致的用户体验。\n• 可扩展：轻松添加新的工具、框架和认证协议，灵活满足业务需求。\n💡 技术亮点\n一行代码集成：快速接入，简化开发流程。 高度自定义：适配不同框架，按需组合工具。 高性能与稳定性：生产级设计，确保工具调用的可靠性和响应速度。 开发者友好：详细文档与示例，助力快速上手。 ","permalink":"https://ansha886.github.io/posts/composio/","title":"Composio：一款面向AI智能体的生产级工具集"},{"content":"一个修复历史文献的AI框架：DiffHDR，它可以预测并修复损坏的历史文献的原始外观支持修复缺失字符、破损纸张、墨迹褪色可以准确还原原始文字内容和风格修复区域与周围背景协调一致\n一个修复历史文献的AI框架：DiffHDR，它可以预测并修复损坏的历史文献的原始外观\n支持修复缺失字符、破损纸张、墨迹褪色 可以准确还原原始文字内容和风格 修复区域与周围背景协调一致\ngithub：https://github.com/yeungchenwa/HDR\n","permalink":"https://ansha886.github.io/posts/diffhdr/","title":"DiffHDR是一个用于修复历史文献的AI框架，能够预测并还原损坏文献的原始外观。"},{"content":"VALL-E X 是 Microsoft 提出的一个令人惊叹的多语言文本转语音 (TTS) 模型，虽然 Microsoft 最初在其研究论文中发布了该模型，但他们没有发布任何代码或预训练模型，团队接受了重现结果的挑战。训练我们自己的模型。\nVALL-E X 是 Microsoft 提出的一个令人惊叹的多语言文本转语音 (TTS) 模型，虽然 Microsoft 最初在其研究论文中发布了该模型，但他们没有发布任何代码或预训练模型，团队接受了重现结果的挑战。训练我们自己的模型。我们很高兴与社区分享我们训练好的 VALL-E X 模型，让大家体验下一代 TTS 的强大功能 🎧\ngithub: https://github.com/Plachtaa/VALL-E-X\n","permalink":"https://ansha886.github.io/posts/vall-e-x/","title":"VALL-E X：微软最新开源多语言文本到语音合成和语音克隆模型"},{"content":"FreeStyle自由！西工大和微软等出的一个说唱(Rap)生成模型：Freestyler，可以根据歌词和伴奏直接生成说唱人声\n酷！西工大和微软等出的一个说唱(Rap)生成模型：Freestyler，可以根据歌词和伴奏直接生成说唱人声，风格以及节奏感跟伴奏匹配度还可以\n歌词+伴奏音乐+3秒的参考人声，即可自动生成与伴奏节奏匹配的说唱人声\n可以模仿指定说唱歌手的音色，且能保持良好的节奏感和自然度\n目前开放了数据集 论文：https://arxiv.org/abs/2408.15474\n数据集：HuggingFace: https://huggingface.co/datasets/zqning/RapBank\nGitHub: https://github.com/NZqian/RapBank\n","permalink":"https://ansha886.github.io/posts/freestyler/","title":"FreeStyle自由！西工大和微软等出的一个说唱(Rap)生成模型：Freestyler，可以根据歌词和伴奏直接生成说唱人声"},{"content":"商学合作，浙大联合快手等的多相机视频生成系统：SynCamMaster，可以从不同视角同步生成视频内容，并保持多个视角下视频内容的一致性\n浙大、快手等的多相机视频生成系统：SynCamMaster，可以从不同视角同步生成视频内容，并保持多个视角下视频内容的一致性。\n项目：https://jianhongbai.github.io/SynCamMaster/\n","permalink":"https://ansha886.github.io/posts/syncammaster/","title":"商学合作，浙大联合快手等的多相机视频生成系统：SynCamMaster，可以从不同视角同步生成视频内容，并保持多个视角下视频内容的一致性"},{"content":"一款本地自动化研究/总结助手：research-rabbit，可以自动深入研究任何主题，提供带有源引用的完整研究报告\n一款本地自动化研究/总结助手：research-rabbit，可以自动深入研究任何主题，提供带有源引用的完整研究报告\n根据主题，生成搜索词搜索网络信息，总结内容，发现不足，继续深入研究，最后生成完整研究报告\n支持免费网络搜索(Tavily API)，可设置研究迭代深度，通过LangGraph Studio可视化过程，输出markdown格式研究报告\ngithub：https://github.com/langchain-ai/research-rabbit\n","permalink":"https://ansha886.github.io/posts/de241dc/","title":"一款本地自动化研究总结助手：research-rabbit，可以自动深入研究任何主题，提供带有源引用的完整研究报告"},{"content":"Show Lab和微软开源的一个基于Qwen2VL架构开发的视觉-语言-动作多模态AI模型：ShowUI，它可以识别和理解用户界面元素，执行比如，点击、输入、选择、滚动等操作，实现GUI自动化。\n能\u0026quot;看\u0026quot;屏幕、\u0026ldquo;懂\u0026quot;指令、会\u0026quot;操作\u0026rdquo;，可以帮你自动操作电脑或手机，不需要写代码，用自然语言即可\n不依赖源代码，它直接通过截图理解界面，自动识别和删减冗余信息，减少33%冗余视觉token，性能提升了1.4倍，零样本界面定位准确率为75.1%\n支持网页和手机界面\ngithub：https://github.com/showlab/ShowUI\n","permalink":"https://ansha886.github.io/posts/show-lab-qwen2vl-ai/","title":"Show Lab和微软开源的一个基于Qwen2VL架构开发的视觉-语言-动作多模态AI模型：ShowUI，它可以识别和理解用户界面元素，执行比如，点击、输入、选择、滚动等操作，实现GUI自动化"},{"content":"Agentless是一款低成本高性能的AI修bug工具，采用无代理的方式，通过定位、修复和补丁验证的三步流程自动解决软件开发问题。在SWE-bench Lite上表现出色，成为所有开源方案中的最高性能工具。\n一个低成本高性能的AI修bug工具：Agentless，采用了一种无代理的方式，自动解决软件开发问题\n在SWE-bench Lite上 在所有开源方案中实现了最高性能\n与Devin等复杂的自主代理方法不同，Agentless用三步解决问题：定位、修复、补丁验证，依据固定流程，LLM只负责在每个特定步骤中完成指定任务即可\ngithub：https://github.com/OpenAutoCoder/Agentless\n论文：https://arxiv.org/pdf/2407.01489\n","permalink":"https://ansha886.github.io/posts/ai-bug-agentless/","title":"一个低成本高性能的AI修bug工具：Agentless，采用了一种无代理的方式，自动解决软件开发问题"},{"content":"可以把各种文件转成Markdown的一个工具：E2M，每种格式有专门的解析器和转换器，支持自定义配置支持doc、docx、epub、html、htm、url、pdf、ppt、pptx、mp3、m4a等用Parser解析器从文件中提取文本和图像，用Converter转换器把提取的内容转为Markdown.\n可以把各种文件转成Markdown的一个工具：E2M，每种格式有专门的解析器和转换器，支持自定义配置\n支持doc、docx、epub、html、htm、url、pdf、ppt、pptx、mp3、m4a等\n用Parser解析器从文件中提取文本和图像，用Converter转换器把提取的内容转为Markdown\ngithub：https://github.com/wisupai/e2m\n","permalink":"https://ansha886.github.io/posts/markdown-e2m/","title":"可以把各种文件类型转成Markdown的一个工具：E2M，每种格式有专门的解析器和转换器，支持自定义配置"},{"content":"酷！DeepSeek刚刚开源了了DeepSeek V2.5的最终版微调模型： DeepSeek-V2.5-1210，新增联网搜索功能， 提升了数学、代码、写作、角色扮演等能力 优化了文件上传功能 新增联网搜索功能。\n酷！DeepSeek刚刚开源了了DeepSeek V2.5的最终版微调模型： DeepSeek-V2.5-1210，新增联网搜索功能\n提升了数学、代码、写作、角色扮演等能力 优化了文件上传功能 新增联网搜索功能\nDeepSeek-V2.5-1210联网搜索功能已上线网页端，登陆 https://chat.deepseek.com/，在输入框中打开“联网搜索”即可体验，目前API不支持搜索功能\n模型：https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210\n","permalink":"https://ansha886.github.io/posts/deepseek-v2-5-model/","title":"DeepSeek刚刚开源了了DeepSeek V2.5的最终版微调模型： DeepSeek-V2.5-1210，新增联网搜索功能"},{"content":"太牛了！Google最新的的量子计算芯片出来了：Willow！ Willow用时不到五分钟完成了一个标准基准计算，而当今最快的超级计算机需要10^25年，远远超过了宇宙的年龄\n太牛了！Google最新的的量子计算芯片出来了：Willow！\nWillow用时不到五分钟完成了一个标准基准计算，而当今最快的超级计算机需要10^25年，远远超过了宇宙的年龄\n博客：https://blog.google/technology/research/google-willow-quantum-chip/\n","permalink":"https://ansha886.github.io/posts/google-willow/","title":"这也太厉害了吧！Google最新的的量子计算芯片出来了：Willow！"},{"content":"Video-LLaVA模型的核心在于其能够提前将图片和视频的特征绑定到统一的特征空间中，这一策略极大地促进了模型对视觉信息的理解和处理能力。与传统的视觉语言模型相比，Video-LLaVA通过联合图片和视频的训练与指令微调，大幅提高了计算效率和模型性能。\n技术创新 Video-LLaVA引入了LanguageBind编码器，这一机制通过预先对齐图片和视频特征来形成统一的视觉表征。这种方法的优势在于无需预先训练各自的图片和视频编码器，从而简化了模型的训练过程，同时也降低了模型对数据的依赖。\n","permalink":"https://ansha886.github.io/posts/video-llava/","title":"北大多模态Video-LLaVA模型：秒懂视频笑点的视觉语言大模型"},{"content":"Meta发布了最新的Llama 3.3-70B模型，具有70亿参数和128K上下文，输入成本比Llama 3.1 405B降低10倍，指令遵循能力超过GPT-4o和Claude 3.5。该模型支持英语、德语、法语等8种语言，适合多语言对话场景，具备良好的性价比，适用于构建聊天机器人等应用。\nMeta刚刚发布了其最新模型：Llama 3.3-70B，性能提升，输入成本比Llama 3.1 405B降低10倍！指令遵循能力超过了GPT-4o、Claude 3.5 Sonnet\nLlama 3.3-70B是一个预训练和指令调优的多语言LLM，专门针对多语言对话场景进行了优化\n1、70B参数，128K上下文 2、多语言，支持英语、德语、法语、意大利语、葡萄牙语、印地语、西班牙语泰语8种语言\n它的通用能力强，多语言支持好，某些指标不如Claude 3.5等模型，数学和推理上有提升空间，总的来说是一个具备性价比的模型，可以构建聊天机器人等。\n型号卡：https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md\n模型：https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct\n","permalink":"https://ansha886.github.io/posts/llama3point3/","title":"Meta刚刚发布了其最新模型：Llama 3.3-70B，性能提升，输入成本比Llama 3.1 405B降低10倍！指令遵循能力超过了GPT-4o、Claude 3.5 Sonnet"},{"content":"Cali是一个AI助手，可以用日常语言描述需求，自动构建运行iOS/Android的React Native应用，管理设备，处理npm包和CocoaPods依赖，并智能搜索React Native库。它可以独立使用，也可以与Vercel AI SDK、Claude、Zed等集成。\n一个可以写React Native应用的AI助手：Cali\n你可以用日常语言描述需求，它可以自动构建运行iOS/Android应用，管理手机/模拟器设备，自动处理npm包和CocoaPods依赖，智能搜索React Native库\n可独立使用，可以和Vercel AI SDK集成，也可以和Claude、Zed等配合使用\ngithub：https://github.com/callstackincubator/cali\n","permalink":"https://ansha886.github.io/posts/react-native-ai-cali/","title":"一个可以写React Native应用的AI助手：Cali"},{"content":"这个效果非常可以，音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度 一张源人物肖像图片+驱动音频，生成可以包含情感表现的面部动作并与音频同步的说话人视频它解决了时间连续的视频生成、由于迭代采样导致速度慢，这两个关键问题\n这个效果非常可以，音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度\n一张源人物肖像图片+驱动音频，生成可以包含情感表现的面部动作并与音频同步的说话人视频\n它解决了时间连续的视频生成、由于迭代采样导致速度慢，这两个关键问题\n项目：https://deepbrainai-research.github.io/float/\n![[dd9BxAP3tY98Zt8CPT12.48S.webp|dd9BxAP3tY98Zt8C - 00:12|50]] 00:12 ","permalink":"https://ansha886.github.io/posts/float/","title":"音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度"},{"content":"这也太厉害了吧！screenshot-to-code 是一款使用 AI 将屏幕截图、模型和 Figma 设计转换为干净、实用的代码的简单工具。现在支持 Claude Sonnet 3.5 和 GPT-4o！\n支持的堆栈：\nHTML + Tailwind HTML + CSS React + Tailwind Vue + Tailwind 引导 Ionic + Tailwind SVG 支持的 AI 模型：\nClaude Sonnet 3.5-最佳模型！ GPT-4o——也推荐！ DALL-E 3 或 Flux Schnell（使用 Replicate）用于图像生成 效果： ","permalink":"https://ansha886.github.io/posts/screenshot-to-code/","title":"screen-to-code 一款使用 AI 将屏幕截图、模型和 Figma 设计转换为干净、实用的代码的简单工具。"},{"content":"效果上，在保留了人物特征、前景/背景的条件下，同时保持了高质量的试穿效果 只需要参考服装图像+源姿势图像+源人物图像输入即可，相比现有方式更经济，用户友好。BooW-VTON主要通过结合数据增强技术和无掩码训练的新范式，从野外场景中生成大规模未配对的训练数据，提高了模型在这些复杂环境中的试穿性能。\n阿里等的虚拟试穿项目：BooW-VTON，它解决了在背景复杂多样的真实环境中进行高质量虚拟试穿的问题\n效果上，在保留了人物特征、前景/背景的条件下，同时保持了高质量的试穿效果 只需要参考服装图像+源姿势图像+源人物图像输入即可，相比现有方式更经济，用户友好\nBooW-VTON主要通过结合数据增强技术和无掩码训练的新范式，从野外场景中生成大规模未配对的训练数据，提高了模型在这些复杂环境中的试穿性能\n论文：https://arxiv.org/pdf/2408.06047 代码还没出呢，会在这里开源，github：https://github.com/little-misfit/BooW-VTON\n#虚拟试穿# #BooWVTON# #AI试衣#\n","permalink":"https://ansha886.github.io/posts/boow-vton/","title":"阿里等的虚拟试穿项目：BooW-VTON，它解决了在背景复杂多样的真实环境中进行高质量虚拟试穿的问题"},{"content":"酷！一个基于AI的多代理研究助手项目：AI-Data-Analysis-MultiAgent，这个agent团队可以自动化完成数据分析、生成研究假设、图表可视化、报告生成等整个流程任务所有agent互相配合，有专门的\u0026quot;笔记助手\u0026quot;记录所有进展，有质量审查，它们可以根据不同任务自动调整工作方式，具备逻辑思维。\n酷！一个基于AI的多代理研究助手项目：AI-Data-Analysis-MultiAgent，这个agent团队可以自动化完成数据分析、生成研究假设、图表可视化、报告生成等整个流程任务\n所有agent互相配合，有专门的\u0026quot;笔记助手\u0026quot;记录所有进展，有质量审查，它们可以根据不同任务自动调整工作方式，具备逻辑思维\n基于LangChain、OpenAI、LangGraph构建.\n可以用它做报告、市场调研、数据分析、学术研究等等.\n构建实时网络代理和浏览器自动化的一个开源工具：steel-browser，它提供了完整的REST API接口来控制浏览器操作\n可以基于它构建比如，AI网页助手、数据采集工具、自动化表格工具等，它可以执行打开网页、截图、下载文件等任务\n开箱即用，支持无头浏览器，支持Docker，支持反检测\n支持基本所有常见的网页操作\n支持并发处理，可以处理大规模任务\n自动处理异常和恢复\n","permalink":"https://ansha886.github.io/posts/ai-data-analysis-multiagent-agent/","title":"一个基于AI的多代理研究助手项目：AI-Data-Analysis-MultiAgent"}]