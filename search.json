[{"categories":["AI"],"content":"IdentityRAG 是一款集成身份识别功能的 RAG 系统，专为企业客户管理设计。它结合了客户数据管理、身份识别与 AI 聊天功能，能够针对特定客户提供准确且具有上下文感知的回答，为企业提升客户管理效率提供了智能化支持。 一个集成了身份识别功能的RAG系统：IdentityRAG，它可以针对特定客户提供准确且具有上下文感知的回答，把客户数据管理、身份识别、AI聊天结合到一起了，适合企业做客户管理使用 支持连接不同的数据源，数据库或者文件，把分散的客户信息汇总起来形成完整的客户档案 它可以识别同一个人的不同记录，会自动合并相关信息 github：https://github.com/tilotech/identity-rag-customer-insights-chatbot ","date":"2024-12-24","objectID":"/posts/identityrag/:0:0","tags":["AI","RAG"],"title":"IdentityRAG 是一款集成身份识别功能的 RAG 系统，专为企业客户管理设计。它结合了客户数据管理、身份识别与 AI 聊天功能，能够针对特定客户提供准确且具有上下文感知的回答，为企业提升客户管理效率提供了智能化支持。","uri":"/posts/identityrag/"},{"categories":["AI","LLM"],"content":"清华和腾讯也开源了一款图像自动上色AI模型：ColorFlow，可以给黑白图像序列上色，特点是能保持角色特征的一致性","date":"2024-12-23","objectID":"/posts/colorflow/","tags":["AI","动画开发"],"title":"清华和腾讯也开源了一款图像自动上色AI模型：ColorFlow，可以给黑白图像序列上色，特点是能保持角色特征的一致性","uri":"/posts/colorflow/"},{"categories":["AI","LLM"],"content":"清华和腾讯也开源了一款图像自动上色AI模型：ColorFlow，可以给黑白图像序列上色，特点是能保持角色特征的一致性 清华和腾讯也开源了一款图像自动上色AI模型：ColorFlow，可以给黑白图像序列上色，特点是能保持角色特征的一致性 用检索增强的方式上色 人物发色、服装等元素的颜色可以保持很好的一致性 github：https://github.com/TencentARC/ColorFlow ","date":"2024-12-23","objectID":"/posts/colorflow/:0:0","tags":["AI","动画开发"],"title":"清华和腾讯也开源了一款图像自动上色AI模型：ColorFlow，可以给黑白图像序列上色，特点是能保持角色特征的一致性","uri":"/posts/colorflow/"},{"categories":["AI"],"content":"通过Composio，轻松为你的AI智能体集成高质量工具和服务，无需操心认证、准确性和可靠性——一行代码即可搞定！","date":"2024-12-19","objectID":"/posts/composio/","tags":["工具","AI"],"title":"Composio：一款面向AI智能体的生产级工具集","uri":"/posts/composio/"},{"categories":["AI"],"content":"通过Composio，轻松为你的AI智能体集成高质量工具和服务，无需操心认证、准确性和可靠性——一行代码即可搞定！ 🔥 核心功能 • 100+ 强大工具支持，涵盖多个领域： • 软件类：GitHub、Notion、Gmail、Slack、HubSpot、Salesforce等90+工具。 • 操作系统类：模拟点击、输入文本、剪贴板操作等。 • 浏览器类：智能搜索、截图、下载、上传等功能。 • 搜索类：Google Search、Perplexity、Tavily、Exa等多种搜索引擎集成。 • 开发工具：Ngrok、数据库、Redis、Vercel、Git等。 • RAG功能：即时检索增强生成（RAG），支持任意类型数据处理。 • 框架兼容性强：与主流AI智能体框架无缝集成： • OpenAI、Groq（兼容OpenAI API）、Claude、LlamaIndex、LangChain、CrewAI、Autogen、Gemini、Julep等。 • 统一授权管理：内置六大认证协议，轻松实现授权： • 支持Access Token、Refresh Token、OAuth、API Key、JWT等，简化接入流程。 • 高准确性：优化工具设计，提升40%+ 智能体工具调用的准确率。 • 可嵌入 \u0026 可扩展： • 可嵌入：支持后端集成，统一管理认证和工具，提供稳定一致的用户体验。 • 可扩展：轻松添加新的工具、框架和认证协议，灵活满足业务需求。 💡 技术亮点 一行代码集成：快速接入，简化开发流程。 高度自定义：适配不同框架，按需组合工具。 高性能与稳定性：生产级设计，确保工具调用的可靠性和响应速度。 开发者友好：详细文档与示例，助力快速上手。 ","date":"2024-12-19","objectID":"/posts/composio/:0:0","tags":["工具","AI"],"title":"Composio：一款面向AI智能体的生产级工具集","uri":"/posts/composio/"},{"categories":["AI"],"content":"一个修复历史文献的AI框架：DiffHDR，它可以预测并修复损坏的历史文献的原始外观支持修复缺失字符、破损纸张、墨迹褪色可以准确还原原始文字内容和风格修复区域与周围背景协调一致","date":"2024-12-19","objectID":"/posts/diffhdr/","tags":["Agent","AI"],"title":"DiffHDR是一个用于修复历史文献的AI框架，能够预测并还原损坏文献的原始外观。","uri":"/posts/diffhdr/"},{"categories":["AI"],"content":"一个修复历史文献的AI框架：DiffHDR，它可以预测并修复损坏的历史文献的原始外观支持修复缺失字符、破损纸张、墨迹褪色可以准确还原原始文字内容和风格修复区域与周围背景协调一致 一个修复历史文献的AI框架：DiffHDR，它可以预测并修复损坏的历史文献的原始外观 支持修复缺失字符、破损纸张、墨迹褪色 可以准确还原原始文字内容和风格 修复区域与周围背景协调一致 github：https://github.com/yeungchenwa/HDR ","date":"2024-12-19","objectID":"/posts/diffhdr/:0:0","tags":["Agent","AI"],"title":"DiffHDR是一个用于修复历史文献的AI框架，能够预测并还原损坏文献的原始外观。","uri":"/posts/diffhdr/"},{"categories":["LLM","AI"],"content":"VALL-E X 是 Microsoft 提出的一个令人惊叹的多语言文本转语音 (TTS) 模型，虽然 Microsoft 最初在其研究论文中发布了该模型，但他们没有发布任何代码或预训练模型，团队接受了重现结果的挑战。训练我们自己的模型。","date":"2024-12-16","objectID":"/posts/vall-e-x/","tags":["TTS","AI","语音"],"title":"VALL-E X：微软最新开源多语言文本到语音合成和语音克隆模型","uri":"/posts/vall-e-x/"},{"categories":["LLM","AI"],"content":"VALL-E X 是 Microsoft 提出的一个令人惊叹的多语言文本转语音 (TTS) 模型，虽然 Microsoft 最初在其研究论文中发布了该模型，但他们没有发布任何代码或预训练模型，团队接受了重现结果的挑战。训练我们自己的模型。 VALL-E X 是 Microsoft 提出的一个令人惊叹的多语言文本转语音 (TTS) 模型，虽然 Microsoft 最初在其研究论文中发布了该模型，但他们没有发布任何代码或预训练模型，团队接受了重现结果的挑战。训练我们自己的模型。我们很高兴与社区分享我们训练好的 VALL-E X 模型，让大家体验下一代 TTS 的强大功能 🎧 github: https://github.com/Plachtaa/VALL-E-X ","date":"2024-12-16","objectID":"/posts/vall-e-x/:0:0","tags":["TTS","AI","语音"],"title":"VALL-E X：微软最新开源多语言文本到语音合成和语音克隆模型","uri":"/posts/vall-e-x/"},{"categories":["AI"],"content":"FreeStyle自由！西工大和微软等出的一个说唱(Rap)生成模型：Freestyler，可以根据歌词和伴奏直接生成说唱人声 酷！西工大和微软等出的一个说唱(Rap)生成模型：Freestyler，可以根据歌词和伴奏直接生成说唱人声，风格以及节奏感跟伴奏匹配度还可以 歌词+伴奏音乐+3秒的参考人声，即可自动生成与伴奏节奏匹配的说唱人声 可以模仿指定说唱歌手的音色，且能保持良好的节奏感和自然度 目前开放了数据集 论文：https://arxiv.org/abs/2408.15474 数据集：HuggingFace: https://huggingface.co/datasets/zqning/RapBank GitHub: https://github.com/NZqian/RapBank ","date":"2024-12-16","objectID":"/posts/freestyler/:0:0","tags":["TTS","AI"],"title":"FreeStyle自由！西工大和微软等出的一个说唱(Rap)生成模型：Freestyler，可以根据歌词和伴奏直接生成说唱人声","uri":"/posts/freestyler/"},{"categories":["AI"],"content":"商学合作，浙大联合快手等的多相机视频生成系统：SynCamMaster，可以从不同视角同步生成视频内容，并保持多个视角下视频内容的一致性","date":"2024-12-14","objectID":"/posts/syncammaster/","tags":["视频","AI"],"title":"商学合作，浙大联合快手等的多相机视频生成系统：SynCamMaster，可以从不同视角同步生成视频内容，并保持多个视角下视频内容的一致性","uri":"/posts/syncammaster/"},{"categories":["AI"],"content":"商学合作，浙大联合快手等的多相机视频生成系统：SynCamMaster，可以从不同视角同步生成视频内容，并保持多个视角下视频内容的一致性 浙大、快手等的多相机视频生成系统：SynCamMaster，可以从不同视角同步生成视频内容，并保持多个视角下视频内容的一致性。 项目：https://jianhongbai.github.io/SynCamMaster/ ","date":"2024-12-14","objectID":"/posts/syncammaster/:0:0","tags":["视频","AI"],"title":"商学合作，浙大联合快手等的多相机视频生成系统：SynCamMaster，可以从不同视角同步生成视频内容，并保持多个视角下视频内容的一致性","uri":"/posts/syncammaster/"},{"categories":["LLM","AIGC"],"content":"一款本地自动化研究/总结助手：research-rabbit，可以自动深入研究任何主题，提供带有源引用的完整研究报告","date":"2024-12-13","objectID":"/posts/de241dc/","tags":["AI","市场调研"],"title":"一款本地自动化研究总结助手：research-rabbit，可以自动深入研究任何主题，提供带有源引用的完整研究报告","uri":"/posts/de241dc/"},{"categories":["LLM","AIGC"],"content":"一款本地自动化研究/总结助手：research-rabbit，可以自动深入研究任何主题，提供带有源引用的完整研究报告 一款本地自动化研究/总结助手：research-rabbit，可以自动深入研究任何主题，提供带有源引用的完整研究报告 根据主题，生成搜索词搜索网络信息，总结内容，发现不足，继续深入研究，最后生成完整研究报告 支持免费网络搜索(Tavily API)，可设置研究迭代深度，通过LangGraph Studio可视化过程，输出markdown格式研究报告 github：https://github.com/langchain-ai/research-rabbit ","date":"2024-12-13","objectID":"/posts/de241dc/:0:0","tags":["AI","市场调研"],"title":"一款本地自动化研究总结助手：research-rabbit，可以自动深入研究任何主题，提供带有源引用的完整研究报告","uri":"/posts/de241dc/"},{"categories":["AIGC"],"content":"Show Lab和微软开源的一个基于Qwen2VL架构开发的视觉-语言-动作多模态AI模型：ShowUI，它可以识别和理解用户界面元素，执行比如，点击、输入、选择、滚动等操作，实现GUI自动化。 能\"看\"屏幕、“懂\"指令、会\"操作”，可以帮你自动操作电脑或手机，不需要写代码，用自然语言即可 不依赖源代码，它直接通过截图理解界面，自动识别和删减冗余信息，减少33%冗余视觉token，性能提升了1.4倍，零样本界面定位准确率为75.1% 支持网页和手机界面 github：https://github.com/showlab/ShowUI ","date":"2024-12-12","objectID":"/posts/show-lab-qwen2vl-ai/:0:0","tags":["AI"],"title":"Show Lab和微软开源的一个基于Qwen2VL架构开发的视觉-语言-动作多模态AI模型：ShowUI，它可以识别和理解用户界面元素，执行比如，点击、输入、选择、滚动等操作，实现GUI自动化","uri":"/posts/show-lab-qwen2vl-ai/"},{"categories":["AI","Agentless"],"content":"Agentless是一款低成本高性能的AI修bug工具，采用无代理的方式，通过定位、修复和补丁验证的三步流程自动解决软件开发问题。在SWE-bench Lite上表现出色，成为所有开源方案中的最高性能工具","date":"2024-12-11","objectID":"/posts/ai-bug-agentless/","tags":["AI"],"title":"一个低成本高性能的AI修bug工具：Agentless，采用了一种无代理的方式，自动解决软件开发问题","uri":"/posts/ai-bug-agentless/"},{"categories":["AI","Agentless"],"content":"Agentless是一款低成本高性能的AI修bug工具，采用无代理的方式，通过定位、修复和补丁验证的三步流程自动解决软件开发问题。在SWE-bench Lite上表现出色，成为所有开源方案中的最高性能工具。 一个低成本高性能的AI修bug工具：Agentless，采用了一种无代理的方式，自动解决软件开发问题 在SWE-bench Lite上 在所有开源方案中实现了最高性能 与Devin等复杂的自主代理方法不同，Agentless用三步解决问题：定位、修复、补丁验证，依据固定流程，LLM只负责在每个特定步骤中完成指定任务即可 github：https://github.com/OpenAutoCoder/Agentless 论文：https://arxiv.org/pdf/2407.01489 ","date":"2024-12-11","objectID":"/posts/ai-bug-agentless/:0:0","tags":["AI"],"title":"一个低成本高性能的AI修bug工具：Agentless，采用了一种无代理的方式，自动解决软件开发问题","uri":"/posts/ai-bug-agentless/"},{"categories":["tools"],"content":"可以把各种文件转成Markdown的一个工具：E2M，每种格式有专门的解析器和转换器，支持自定义配置**支持doc、docx、epub、html、htm、url、pdf、ppt、pptx、mp3、m4a等用Parser解析器从文件中提取文本和图像，用Converter转换器把提取的内容转为Markdown","date":"2024-12-11","objectID":"/posts/markdown-e2m/","tags":["文件类型转换","Markdown"],"title":"可以把各种文件类型转成Markdown的一个工具：E2M，每种格式有专门的解析器和转换器，支持自定义配置","uri":"/posts/markdown-e2m/"},{"categories":["tools"],"content":"可以把各种文件转成Markdown的一个工具：E2M，每种格式有专门的解析器和转换器，支持自定义配置支持doc、docx、epub、html、htm、url、pdf、ppt、pptx、mp3、m4a等用Parser解析器从文件中提取文本和图像，用Converter转换器把提取的内容转为Markdown. 可以把各种文件转成Markdown的一个工具：E2M，每种格式有专门的解析器和转换器，支持自定义配置 支持doc、docx、epub、html、htm、url、pdf、ppt、pptx、mp3、m4a等 用Parser解析器从文件中提取文本和图像，用Converter转换器把提取的内容转为Markdown github：https://github.com/wisupai/e2m ","date":"2024-12-11","objectID":"/posts/markdown-e2m/:0:0","tags":["文件类型转换","Markdown"],"title":"可以把各种文件类型转成Markdown的一个工具：E2M，每种格式有专门的解析器和转换器，支持自定义配置","uri":"/posts/markdown-e2m/"},{"categories":["LLM","AI"],"content":"酷！DeepSeek刚刚开源了了DeepSeek V2.5的最终版微调模型： DeepSeek-V2.5-1210，新增联网搜索功能， 提升了数学、代码、写作、角色扮演等能力 优化了文件上传功能 新增联网搜索功能。 酷！DeepSeek刚刚开源了了DeepSeek V2.5的最终版微调模型： DeepSeek-V2.5-1210，新增联网搜索功能 提升了数学、代码、写作、角色扮演等能力 优化了文件上传功能 新增联网搜索功能 DeepSeek-V2.5-1210联网搜索功能已上线网页端，登陆 https://chat.deepseek.com/，在输入框中打开“联网搜索”即可体验，目前API不支持搜索功能 模型：https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210 ","date":"2024-12-11","objectID":"/posts/deepseek-v2-5-model/:0:0","tags":["Llama3","DeepSeek"],"title":"DeepSeek刚刚开源了了DeepSeek V2.5的最终版微调模型： DeepSeek-V2.5-1210，新增联网搜索功能","uri":"/posts/deepseek-v2-5-model/"},{"categories":["LLM"],"content":"Google最新的量子计算芯片Willow在不到五分钟内完成了一个标准基准计算，而当前最快的超级计算机需要10^25年才能完成同样的任务，远超宇宙的年龄","date":"2024-12-10","objectID":"/posts/google-willow/","tags":["量子计算"],"title":"这也太厉害了吧！Google最新的的量子计算芯片出来了：Willow！","uri":"/posts/google-willow/"},{"categories":["LLM"],"content":"太牛了！Google最新的的量子计算芯片出来了：Willow！ Willow用时不到五分钟完成了一个标准基准计算，而当今最快的超级计算机需要10^25年，远远超过了宇宙的年龄 太牛了！Google最新的的量子计算芯片出来了：Willow！ Willow用时不到五分钟完成了一个标准基准计算，而当今最快的超级计算机需要10^25年，远远超过了宇宙的年龄 博客：https://blog.google/technology/research/google-willow-quantum-chip/ ","date":"2024-12-10","objectID":"/posts/google-willow/:0:0","tags":["量子计算"],"title":"这也太厉害了吧！Google最新的的量子计算芯片出来了：Willow！","uri":"/posts/google-willow/"},{"categories":["LLM"],"content":"Video-LLaVA模型的核心在于其能够提前将图片和视频的特征绑定到统一的特征空间中，这一策略极大地促进了模型对视觉信息的理解和处理能力。与传统的视觉语言模型相比，Video-LLaVA通过联合图片和视频的训练与指令微调，大幅提高了计算效率和模型性能。","date":"2024-12-09","objectID":"/posts/video-llava/","tags":["AI","LLaVA"],"title":"北大多模态Video-LLaVA模型：秒懂视频笑点的视觉语言大模型","uri":"/posts/video-llava/"},{"categories":["LLM"],"content":"Video-LLaVA模型的核心在于其能够提前将图片和视频的特征绑定到统一的特征空间中，这一策略极大地促进了模型对视觉信息的理解和处理能力。与传统的视觉语言模型相比，Video-LLaVA通过联合图片和视频的训练与指令微调，大幅提高了计算效率和模型性能。 技术创新 Video-LLaVA引入了LanguageBind编码器，这一机制通过预先对齐图片和视频特征来形成统一的视觉表征。这种方法的优势在于无需预先训练各自的图片和视频编码器，从而简化了模型的训练过程，同时也降低了模型对数据的依赖。 ","date":"2024-12-09","objectID":"/posts/video-llava/:0:0","tags":["AI","LLaVA"],"title":"北大多模态Video-LLaVA模型：秒懂视频笑点的视觉语言大模型","uri":"/posts/video-llava/"},{"categories":["LLM"],"content":"Meta刚刚发布了其最新模型：Llama 3.3-70B，性能提升，输入成本比Llama 3.1 405B降低10倍！指令遵循能力超过了GPT-4o、Claude 3.5 Sonnet","date":"2024-12-09","objectID":"/posts/llama3point3/","tags":["Llama3","AI"],"title":"Meta刚刚发布了其最新模型：Llama 3.3-70B，性能提升，输入成本比Llama 3.1 405B降低10倍！指令遵循能力超过了GPT-4o、Claude 3.5 Sonnet","uri":"/posts/llama3point3/"},{"categories":["LLM"],"content":"Meta发布了最新的Llama 3.3-70B模型，具有70亿参数和128K上下文，输入成本比Llama 3.1 405B降低10倍，指令遵循能力超过GPT-4o和Claude 3.5。该模型支持英语、德语、法语等8种语言，适合多语言对话场景，具备良好的性价比，适用于构建聊天机器人等应用。 Meta刚刚发布了其最新模型：Llama 3.3-70B，性能提升，输入成本比Llama 3.1 405B降低10倍！指令遵循能力超过了GPT-4o、Claude 3.5 Sonnet Llama 3.3-70B是一个预训练和指令调优的多语言LLM，专门针对多语言对话场景进行了优化 1、70B参数，128K上下文 2、多语言，支持英语、德语、法语、意大利语、葡萄牙语、印地语、西班牙语泰语8种语言 它的通用能力强，多语言支持好，某些指标不如Claude 3.5等模型，数学和推理上有提升空间，总的来说是一个具备性价比的模型，可以构建聊天机器人等。 型号卡：https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md 模型：https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct ","date":"2024-12-09","objectID":"/posts/llama3point3/:0:0","tags":["Llama3","AI"],"title":"Meta刚刚发布了其最新模型：Llama 3.3-70B，性能提升，输入成本比Llama 3.1 405B降低10倍！指令遵循能力超过了GPT-4o、Claude 3.5 Sonnet","uri":"/posts/llama3point3/"},{"categories":["AI"],"content":"Cali是一个AI助手，可以用日常语言描述需求，自动构建运行iOS/Android的React Native应用，管理设备，处理npm包和CocoaPods依赖，并智能搜索React Native库。它可以独立使用，也可以与Vercel AI SDK、Claude、Zed等集成。","date":"2024-12-06","objectID":"/posts/react-native-ai-cali/","tags":["AIAgent"],"title":"一个可以写React Native应用的AI助手：Cali","uri":"/posts/react-native-ai-cali/"},{"categories":["AI"],"content":"Cali是一个AI助手，可以用日常语言描述需求，自动构建运行iOS/Android的React Native应用，管理设备，处理npm包和CocoaPods依赖，并智能搜索React Native库。它可以独立使用，也可以与Vercel AI SDK、Claude、Zed等集成。 一个可以写React Native应用的AI助手：Cali 你可以用日常语言描述需求，它可以自动构建运行iOS/Android应用，管理手机/模拟器设备，自动处理npm包和CocoaPods依赖，智能搜索React Native库 可独立使用，可以和Vercel AI SDK集成，也可以和Claude、Zed等配合使用 github：https://github.com/callstackincubator/cali ","date":"2024-12-06","objectID":"/posts/react-native-ai-cali/:0:0","tags":["AIAgent"],"title":"一个可以写React Native应用的AI助手：Cali","uri":"/posts/react-native-ai-cali/"},{"categories":["LLM"],"content":"音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度","date":"2024-12-04","objectID":"/posts/float/","tags":["AI","TTS"],"title":"音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度","uri":"/posts/float/"},{"categories":["LLM"],"content":"这个效果非常可以，音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度 一张源人物肖像图片+驱动音频，生成可以包含情感表现的面部动作并与音频同步的说话人视频它解决了时间连续的视频生成、由于迭代采样导致速度慢，这两个关键问题 这个效果非常可以，音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度 一张源人物肖像图片+驱动音频，生成可以包含情感表现的面部动作并与音频同步的说话人视频 它解决了时间连续的视频生成、由于迭代采样导致速度慢，这两个关键问题 项目：https://deepbrainai-research.github.io/float/ ![[dd9BxAP3tY98Zt8CPT12.48S.webp|dd9BxAP3tY98Zt8C - 00:12|50]] 00:12 ","date":"2024-12-04","objectID":"/posts/float/:0:0","tags":["AI","TTS"],"title":"音频驱动说话人肖像视频生成模型：FLOAT，保真度很高，且支持情感增强和控制，能调节情感表现的强度","uri":"/posts/float/"},{"categories":["LLM"],"content":"screenshot-to-code 一款使用 AI 将屏幕截图、模型和 Figma 设计转换为干净、实用的代码的简单工具。现在支持 Claude Sonnet 3.5 和 GPT-4o！","date":"2024-12-03","objectID":"/posts/screenshot-to-code/","tags":["AI","AIAgent"],"title":"screen-to-code 一款使用 AI 将屏幕截图、模型和 Figma 设计转换为干净、实用的代码的简单工具。","uri":"/posts/screenshot-to-code/"},{"categories":["LLM"],"content":"这也太厉害了吧！screenshot-to-code 是一款使用 AI 将屏幕截图、模型和 Figma 设计转换为干净、实用的代码的简单工具。现在支持 Claude Sonnet 3.5 和 GPT-4o！ 支持的堆栈： HTML + Tailwind HTML + CSS React + Tailwind Vue + Tailwind 引导 Ionic + Tailwind SVG 支持的 AI 模型： Claude Sonnet 3.5-最佳模型！ GPT-4o——也推荐！ DALL-E 3 或 Flux Schnell（使用 Replicate）用于图像生成 效果： ","date":"2024-12-03","objectID":"/posts/screenshot-to-code/:0:0","tags":["AI","AIAgent"],"title":"screen-to-code 一款使用 AI 将屏幕截图、模型和 Figma 设计转换为干净、实用的代码的简单工具。","uri":"/posts/screenshot-to-code/"},{"categories":["LLM"],"content":"阿里等的虚拟试穿项目：BooW-VTON，它解决了在背景复杂多样的真实环境中进行高质量虚拟试穿的问题","date":"2024-12-02","objectID":"/posts/boow-vton/","tags":["AIGC","Agent"],"title":"阿里等的虚拟试穿项目：BooW-VTON，它解决了在背景复杂多样的真实环境中进行高质量虚拟试穿的问题","uri":"/posts/boow-vton/"},{"categories":["LLM"],"content":"效果上，在保留了人物特征、前景/背景的条件下，同时保持了高质量的试穿效果 只需要参考服装图像+源姿势图像+源人物图像输入即可，相比现有方式更经济，用户友好。BooW-VTON主要通过结合数据增强技术和无掩码训练的新范式，从野外场景中生成大规模未配对的训练数据，提高了模型在这些复杂环境中的试穿性能。 阿里等的虚拟试穿项目：BooW-VTON，它解决了在背景复杂多样的真实环境中进行高质量虚拟试穿的问题 效果上，在保留了人物特征、前景/背景的条件下，同时保持了高质量的试穿效果 只需要参考服装图像+源姿势图像+源人物图像输入即可，相比现有方式更经济，用户友好 BooW-VTON主要通过结合数据增强技术和无掩码训练的新范式，从野外场景中生成大规模未配对的训练数据，提高了模型在这些复杂环境中的试穿性能 论文：https://arxiv.org/pdf/2408.06047 代码还没出呢，会在这里开源，github：https://github.com/little-misfit/BooW-VTON #虚拟试穿# #BooWVTON# #AI试衣# ","date":"2024-12-02","objectID":"/posts/boow-vton/:0:0","tags":["AIGC","Agent"],"title":"阿里等的虚拟试穿项目：BooW-VTON，它解决了在背景复杂多样的真实环境中进行高质量虚拟试穿的问题","uri":"/posts/boow-vton/"},{"categories":["LLM"],"content":"AI-Data-Analysis-MultiAgent是一个基于AI的多代理研究助手项目，能够自动化完成数据分析、生成研究假设、图表可视化和报告生成等任务。该项目利用LangChain、OpenAI和LangGraph构建，所有代理协作并具备逻辑思维，适用于报告、市场调研、数据分析和学术研究等领域。","date":"2024-11-26","objectID":"/posts/ai-data-analysis-multiagent-agent/","tags":["AIGC","AI","Agent"],"title":"一个基于AI的多代理研究助手项目：AI-Data-Analysis-MultiAgent","uri":"/posts/ai-data-analysis-multiagent-agent/"},{"categories":["LLM"],"content":"酷！一个基于AI的多代理研究助手项目：AI-Data-Analysis-MultiAgent，这个agent团队可以自动化完成数据分析、生成研究假设、图表可视化、报告生成等整个流程任务所有agent互相配合，有专门的\"笔记助手\"记录所有进展，有质量审查，它们可以根据不同任务自动调整工作方式，具备逻辑思维。 酷！一个基于AI的多代理研究助手项目：AI-Data-Analysis-MultiAgent，这个agent团队可以自动化完成数据分析、生成研究假设、图表可视化、报告生成等整个流程任务 所有agent互相配合，有专门的\"笔记助手\"记录所有进展，有质量审查，它们可以根据不同任务自动调整工作方式，具备逻辑思维 基于LangChain、OpenAI、LangGraph构建. 可以用它做报告、市场调研、数据分析、学术研究等等. 构建实时网络代理和浏览器自动化的一个开源工具：steel-browser，它提供了完整的REST API接口来控制浏览器操作 可以基于它构建比如，AI网页助手、数据采集工具、自动化表格工具等，它可以执行打开网页、截图、下载文件等任务 开箱即用，支持无头浏览器，支持Docker，支持反检测 支持基本所有常见的网页操作 支持并发处理，可以处理大规模任务 自动处理异常和恢复 ","date":"2024-11-26","objectID":"/posts/ai-data-analysis-multiagent-agent/:0:0","tags":["AIGC","AI","Agent"],"title":"一个基于AI的多代理研究助手项目：AI-Data-Analysis-MultiAgent","uri":"/posts/ai-data-analysis-multiagent-agent/"}]